{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64deccb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fccc364bbe04a6494e2c0ac21bbbcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b755bdfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
      "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mdatasets==4.1.1                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mdatasets==4.1.1                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mfilelock==3.13.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mpyarrow==21.0.0                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mdill==0.4.0                                                                   \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mpandas==2.3.2                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mxxhash==3.5.0                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mmultiprocess==0.70.16                                                         \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠼\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠴\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠦\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠧\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠇\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mpython-dateutil==2.9.0.post0                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mpytz==2025.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mtzdata==2025.2                                                                \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mcharset-normalizer==3.4.3                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2midna==3.10                                                                    \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2murllib3==2.5.0                                                                \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mcertifi==2024.8.30                                                            \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2maiohttp==3.10.8                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mtyping-extensions==4.12.2                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mhf-xet==1.1.9                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mhf-xet==1.1.9                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2msix==1.17.0                                                                   \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2maiohappyeyeballs==2.4.3                                                       \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2maiosignal==1.3.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mattrs==24.2.0                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mfrozenlist==1.4.1                                                             \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mmultidict==6.1.0                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2myarl==1.13.1                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2m                                                                              \u001b[0m\r",
      "\u001b[2K\u001b[2mResolved \u001b[1m31 packages\u001b[0m \u001b[2min 2.36s\u001b[0m\u001b[0m\r\n",
      "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r",
      "\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)                                                   \r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)                                                   \r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/143.30 KiB                  \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.92 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 30.92 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 46.92 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 62.92 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 74.96 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 90.96 KiB/143.30 KiB                \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 106.96 KiB/143.30 KiB               \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.96 KiB/143.30 KiB               \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB               \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/189.82 KiB                    \u001b[2A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB                  \u001b[2A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/40.85 MiB                     \u001b[3A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/40.85 MiB                   \u001b[3A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/116.86 KiB\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/40.85 MiB                   \u001b[4A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/116.86 KiB\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/40.85 MiB                   \u001b[5A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/116.86 KiB\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.91 KiB/189.82 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.88 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/40.85 MiB                   \u001b[5A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 48.00 KiB/116.86 KiB\r\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.96 KiB/143.30 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.91 KiB/189.82 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.77 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.90 KiB/40.85 MiB                   \u001b[5A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.00 KiB/116.86 KiB\r\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 188.49 KiB/189.82 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 158.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 511.53 KiB/40.85 MiB                  \u001b[4A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.00 KiB/116.86 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 190.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 607.53 KiB/40.85 MiB                  \u001b[3A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 96.00 KiB/116.86 KiB\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 238.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.05 MiB/40.85 MiB                    \u001b[3A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 302.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.93 MiB/40.85 MiB                    \u001b[2A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 318.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.42 MiB/40.85 MiB                    \u001b[2A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
      "\u001b[2mdatasets  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 366.33 KiB/491.82 KiB\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 4.62 MiB/40.85 MiB                    \u001b[2A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 6.07 MiB/40.85 MiB                    \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 6.08 MiB/40.85 MiB                    \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 8.08 MiB/40.85 MiB                    \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 10.08 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 12.00 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 14.08 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 15.92 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 17.39 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 18.93 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 21.38 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 22.98 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 24.42 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 27.08 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 28.70 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 29.79 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 30.47 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 30.53 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 30.67 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 32.03 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 33.82 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 35.78 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 38.39 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 39.06 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 39.37 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 39.70 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.12 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
      "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.59 MiB/40.85 MiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)                                                   \r",
      "\u001b[2K\u001b[2mPrepared \u001b[1m5 packages\u001b[0m \u001b[2min 1.52s\u001b[0m\u001b[0m\r\n",
      "░░░░░░░░░░░░░░░░░░░░ [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/5] \u001b[2mInstalling wheels...                                 \u001b[0m\r",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/5] \u001b[2mxxhash==3.5.0                                        \u001b[0m\r",
      "\u001b[2K████░░░░░░░░░░░░░░░░ [1/5] \u001b[2mxxhash==3.5.0                                        \u001b[0m\r",
      "\u001b[2K████░░░░░░░░░░░░░░░░ [1/5] \u001b[2mmultiprocess==0.70.16                                \u001b[0m\r",
      "\u001b[2K████████░░░░░░░░░░░░ [2/5] \u001b[2mmultiprocess==0.70.16                                \u001b[0m\r",
      "\u001b[2K████████░░░░░░░░░░░░ [2/5] \u001b[2mdill==0.4.0                                          \u001b[0m\r",
      "\u001b[2K████████████░░░░░░░░ [3/5] \u001b[2mdill==0.4.0                                          \u001b[0m\r",
      "\u001b[2K████████████░░░░░░░░ [3/5] \u001b[2mdatasets==4.1.1                                      \u001b[0m\r",
      "\u001b[2K████████████████░░░░ [4/5] \u001b[2mdatasets==4.1.1                                      \u001b[0m\r",
      "\u001b[2K████████████████░░░░ [4/5] \u001b[2mpyarrow==21.0.0                                      \u001b[0m\r",
      "\u001b[2K████████████████████ [5/5] \u001b[2mpyarrow==21.0.0                                      \u001b[0m\r",
      "\u001b[2K\u001b[2mInstalled \u001b[1m5 packages\u001b[0m \u001b[2min 206ms\u001b[0m\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.1.1\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==21.0.0\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.5.0\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d653999f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500aed5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
      "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mevaluate==0.4.6                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mdatasets==4.1.1                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mdill==0.4.0                                                                   \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpandas==2.3.2                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mxxhash==3.5.0                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mmultiprocess==0.70.16                                                         \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfilelock==3.13.1                                                              \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpyarrow==21.0.0                                                               \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpython-dateutil==2.9.0.post0                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpytz==2025.2                                                                  \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtzdata==2025.2                                                                \u001b[0m\r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfrozenlist==1.4.1                                                             \u001b[0m\r",
      "\u001b[2K\u001b[2mResolved \u001b[1m32 packages\u001b[0m \u001b[2min 164ms\u001b[0m\u001b[0m\r\n",
      "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r",
      "\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/82.10 KiB                     \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 16.00 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 32.00 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 48.00 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 64.00 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 80.00 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
      "\u001b[2mevaluate  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 82.10 KiB/82.10 KiB                   \u001b[1A\r",
      "\u001b[2K\u001b[1B\r",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m\u001b[0m (1/1)                                                                        \r",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m\r\n",
      "░░░░░░░░░░░░░░░░░░░░ [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mevaluate==0.4.6                                      \u001b[0m\r",
      "\u001b[2K████████████████████ [1/1] \u001b[2mevaluate==0.4.6                                      \u001b[0m\r",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m\r\n",
      " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7a556",
   "metadata": {},
   "source": [
    "## Data Preparation - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390f257e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "BRIEF_PROMPTS = {\n",
    "    'default': \"Answer the following question as briefly as possible.\\n\",\n",
    "    'chat': 'Answer the following question in a single brief but complete sentence.\\n'}\n",
    "\n",
    "md5hash = lambda s: str(int(hashlib.md5(s.encode('utf-8')).hexdigest(), 16))\n",
    "\n",
    "\n",
    "def construct_few_shot_prompt_from_indices(dataset, example_indices, brief, brief_always, make_prompt):\n",
    "    \"\"\"\n",
    "        Given a dataset and indices, construct a few-shot prompt.\n",
    "        :param dataset:\n",
    "        :param example_indices:\n",
    "        :param brief:\n",
    "        :param brief_always:\n",
    "        :param make_prompt:\n",
    "\n",
    "    \"\"\"\n",
    "    if not brief_always:\n",
    "        prompt = brief\n",
    "    else:\n",
    "        prompt = ''\n",
    "\n",
    "    for example_index in example_indices:\n",
    "        example = dataset[example_index]\n",
    "        if 'context' in example.keys():\n",
    "            context = example[\"context\"]\n",
    "        else:\n",
    "            context = None\n",
    "\n",
    "        question = example[\"question\"]\n",
    "        answer = example[\"numerical_answer\"]\n",
    "\n",
    "        prompt = prompt + make_prompt(context, question, answer, brief, brief_always)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_make_prompt(prompt_type, use_context):\n",
    "    if prompt_type == 'default':\n",
    "        def make_prompt(context, question, answer, brief, brief_always):\n",
    "            prompt = ''\n",
    "            if brief_always:\n",
    "                prompt += brief\n",
    "            if use_context and (context is not None):\n",
    "                prompt += f\"Context: {context}\\n\"\n",
    "            prompt += f\"Question: {question}\\n\"\n",
    "            if answer:\n",
    "                prompt += f\"Answer: {answer}\\n\\n\"\n",
    "            else:\n",
    "                prompt += 'Answer:'\n",
    "            return prompt\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return make_prompt\n",
    "\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    \"\"\"\n",
    "        Get indices of answerable and unanswerable questions.\n",
    "        :param dataset:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    answerable_indices = [i for i, example in enumerate(dataset) if example['answer_length'] > 0]\n",
    "    unanswerable_indices = [i for i, example in enumerate(dataset) if example['answer_length'] == 0]\n",
    "\n",
    "    return answerable_indices, unanswerable_indices\n",
    "\n",
    "\n",
    "def dataset_pre_process(example):\n",
    "    example['answer_explanation'] = example['answer']\n",
    "\n",
    "    answer_str = example['answer'].split('#### ')[-1].strip().replace(',', '')\n",
    "    int_answer = int(answer_str)\n",
    "    fl_answer = float(answer_str)\n",
    "\n",
    "    example['id'] = md5hash(str(example['question']))\n",
    "    example['answer_length'] = len(answer_str)\n",
    "\n",
    "    if int_answer == fl_answer:\n",
    "        example['answer_numerical_type'] = 'int'\n",
    "        example['numerical_answer'] = int_answer\n",
    "    else:\n",
    "        example['answer_numerical_type'] = 'float'\n",
    "        example['numerical_answer'] = fl_answer\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "def load_ds(dataset_name):\n",
    "    \"\"\"\n",
    "        Load dataset\n",
    "\n",
    "    \"\"\"\n",
    "    train_dt, validation_dt = None, None\n",
    "    if dataset_name == \"gsm8k\":\n",
    "        dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "        dataset = dataset.map(dataset_pre_process)\n",
    "\n",
    "        dataset = dataset.filter(lambda x: x['id']!='229204758988173734073362288035613840709')\n",
    "\n",
    "        test_valid_split = dataset['test'].train_test_split(test_size=0.3)\n",
    "        train_dt = dataset[\"train\"]\n",
    "        validation_dt = test_valid_split[\"test\"]\n",
    "\n",
    "    return train_dt.select(range(2000)), validation_dt\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name, experiment_details, num_few_shot, running_parameters):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dataset_name:\n",
    "    :param experiment_details:\n",
    "    :param num_few_shot:\n",
    "    :param running_parameters: brief_prompt, brief_always, enable_brief, use_context\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataset, validation_dataset = load_ds(dataset_name)\n",
    "    answerable_indices, unanswerable_indices = split_dataset(train_dataset)\n",
    "\n",
    "    prompt_indices = random.sample(answerable_indices, num_few_shot)\n",
    "    experiment_details['prompt_indices'] = prompt_indices\n",
    "    remaining_answerable = list(set(answerable_indices) - set(prompt_indices))\n",
    "\n",
    "    BRIEF = BRIEF_PROMPTS[running_parameters['brief_prompt']]\n",
    "    arg = running_parameters['brief_always'] if running_parameters['enable_brief'] else True\n",
    "    make_prompt = get_make_prompt(prompt_type='default', use_context=running_parameters['use_context'])\n",
    "    prompt = construct_few_shot_prompt_from_indices(train_dataset, prompt_indices, BRIEF, arg, make_prompt)\n",
    "\n",
    "    experiment_details['BRIEF'] = BRIEF\n",
    "    experiment_details['prompt'] = prompt\n",
    "\n",
    "    return train_dataset, validation_dataset, answerable_indices, unanswerable_indices, remaining_answerable, experiment_details\n",
    "\n",
    "## Testing Code\n",
    "# experiment_details = {}\n",
    "# running_parameters = {'brief_prompt': 'default', 'brief_always': False, 'enable_brief': True, 'use_context': False}\n",
    "# tr_dt, vl_dt, ans_ind, unans_ind, rm_answ, exp = get_dataset('gsm8k', experiment_details, 5, running_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b7bc4",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ec86e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "def get_reference(example):\n",
    "    if 'numerical_answer' not in example:\n",
    "        example = example['answer_explanation']\n",
    "\n",
    "    answers = example['numerical_answer']\n",
    "\n",
    "    answer_starts = example['answer'].rfind(str(answers))\n",
    "\n",
    "    if answer_starts == -1:\n",
    "        answer_starts = []\n",
    "\n",
    "    reference = {'answers': {'answer_start': [answer_starts], 'text': [str(example['numerical_answer'])]}, 'id': example['id']}\n",
    "    return reference\n",
    "\n",
    "\n",
    "def get_metric(metric):\n",
    "    if metric == 'squad':\n",
    "\n",
    "        squad_metric = load(\"squad_v2\")\n",
    "\n",
    "        def metric(response, example, *args, **kwargs):\n",
    "            # Compatibility with recomputation.\n",
    "            if 'id' in example:\n",
    "                exid = example['id']\n",
    "            elif 'id' in example['reference']:\n",
    "                exid = example['reference']['id']\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            prediction = {'prediction_text': response, 'no_answer_probability': 0.0, 'id': exid}\n",
    "            results = squad_metric.compute(\n",
    "                predictions=[prediction],\n",
    "                references=[get_reference(example)])\n",
    "            return 1.0 if (results['f1'] >= 50.0) else 0.0\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "def save(object, file):\n",
    "    with open(f'{file}', 'wb') as f:\n",
    "        pickle.dump(object, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b0e2f",
   "metadata": {},
   "source": [
    "## Model Initialisation and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c19aec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "stop_sequences = ['\\n\\n\\n\\n', '\\n\\n\\n', 'Question:', 'Context:']\n",
    "# '\\n\\n', '\\n',\n",
    "\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "    \"\"\"\n",
    "        Stop generations when they match a particular text or token.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stops, tokenizer, match_on='text', initial_length=None):\n",
    "        super().__init__()\n",
    "        self.stops = stops\n",
    "        self.initial_length = initial_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.match_on = match_on\n",
    "        if self.match_on == 'tokens':\n",
    "            self.stops = [torch.tensor(self.tokenizer.encode(i))  # .to('cuda')\n",
    "                          for i in self.stops]\n",
    "            print(self.stops)\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs):\n",
    "        del scores\n",
    "        for stop in self.stops:\n",
    "            if self.match_on == 'text':\n",
    "                generation = self.tokenizer.decode(input_ids[0][self.initial_length:], skip_special_tokens=False)\n",
    "                match = stop in generation\n",
    "            elif self.match_on == 'tokens':\n",
    "                # Can be dangerous due to tokenizer ambiguities.\n",
    "                match = stop in input_ids[0][-len(stop):]\n",
    "            else:\n",
    "                raise\n",
    "            if match:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def model_init(model_name):\n",
    "    \"\"\"\n",
    "        Model Initialization\n",
    "\n",
    "        :param model_name:\n",
    "        :return:\n",
    "    \"\"\"\n",
    "    tokenizer, model = None, None\n",
    "    if model_name == 'Mistral-7B-v0.1':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\",\n",
    "                                                  token_type_ids=None, clean_up_tokenization_spaces=False)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\",\n",
    "                                                     attn_implementation='eager', max_memory={0: '80GIB'})\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def model_predict(model, tokenizer, input_data, temperature, max_new_tokens, return_latent=False):\n",
    "\n",
    "    token_limit = 2048\n",
    "    stop_seq = stop_sequences + [tokenizer.eos_token]\n",
    "\n",
    "    inputs = tokenizer(input_data, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    \n",
    "\n",
    "    if 'token_type_ids' in inputs:  # HF models seems has changed.\n",
    "        del inputs['token_type_ids']\n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "    else:\n",
    "        pad_token_id = None\n",
    "\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    if stop_seq is not None:\n",
    "        stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(\n",
    "            stops=stop_seq,\n",
    "            initial_length=len(inputs['input_ids'][0]),\n",
    "            tokenizer=tokenizer)])\n",
    "    else:\n",
    "        stopping_criteria = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            output_hidden_states=True,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            pad_token_id=pad_token_id,\n",
    "        )\n",
    "\n",
    "    if len(outputs.sequences[0]) > token_limit:\n",
    "        raise ValueError(\n",
    "            'Generation exceeding token limit %d > %d', len(outputs.sequences[0]), token_limit)\n",
    "\n",
    "    full_answer = tokenizer.decode(\n",
    "        outputs.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "    if full_answer.startswith(input_data):\n",
    "        input_data_offset = len(input_data)\n",
    "    else:\n",
    "        input_data_offset = 0\n",
    "\n",
    "    # Remove input from answer.\n",
    "    answer = full_answer[input_data_offset:]\n",
    "\n",
    "    # Remove stop_words from answer.\n",
    "    stop_at = len(answer)\n",
    "    sliced_answer = answer\n",
    "\n",
    "    if stop_seq is not None:\n",
    "        for stop in stop_seq:\n",
    "            if answer.endswith(stop):\n",
    "                stop_at = len(answer) - len(stop)\n",
    "                sliced_answer = answer[:stop_at]\n",
    "                break\n",
    "        if not all([stop not in sliced_answer for stop in stop_seq]):\n",
    "            error_msg = 'Error: Stop words not removed successfully!'\n",
    "            error_msg += f'Answer: >{answer}< '\n",
    "            error_msg += f'Sliced Answer: >{sliced_answer}<'\n",
    "            print(error_msg)\n",
    "\n",
    "    # Remove whitespaces from answer (in particular from beginning.)\n",
    "    sliced_answer = sliced_answer.strip()\n",
    "    token_stop_index = tokenizer(full_answer[:input_data_offset + stop_at], return_tensors=\"pt\")['input_ids'].shape[1]\n",
    "    n_input_token = len(inputs['input_ids'][0])\n",
    "    n_generated = token_stop_index - n_input_token\n",
    "\n",
    "    return_latent = True\n",
    "\n",
    "    if n_generated == 0:\n",
    "        print('Only stop_words were generated. For likelihoods and embeddings, taking stop word instead.')\n",
    "        n_generated = 1\n",
    "\n",
    "    if 'decoder_hidden_states' in outputs.keys():\n",
    "        hidden = outputs.decoder_hidden_states\n",
    "    else:\n",
    "        hidden = outputs.hidden_states\n",
    "\n",
    "    if len(hidden) == 1:\n",
    "        last_input = hidden[0]\n",
    "    elif (n_generated - 1) >= len(hidden):\n",
    "        # if access idx is larger/equal\n",
    "        last_input = hidden[-1]\n",
    "    else:\n",
    "        last_input = hidden[n_generated - 1]\n",
    "\n",
    "    last_layer = last_input[-1]\n",
    "    last_token_embedding = last_layer[:, -1, :].cpu()\n",
    "\n",
    "    if return_latent:\n",
    "        # Stack second last token embeddings from all layers\n",
    "        if len(hidden) == 1:\n",
    "            sec_last_input = hidden[0]\n",
    "        elif (n_generated - 2) >= len(hidden):\n",
    "            sec_last_input = hidden[-2]\n",
    "        else:\n",
    "            sec_last_input = hidden[n_generated - 2]\n",
    "        sec_last_token_embedding = torch.stack([layer[:, -1, :] for layer in sec_last_input]).cpu()\n",
    "\n",
    "        # Get the last input token embeddings (before generated tokens)\n",
    "        last_tok_bef_gen_input = hidden[0]\n",
    "        last_tok_bef_gen_embedding = torch.stack([layer[:, -1, :] for layer in last_tok_bef_gen_input]).cpu()\n",
    "\n",
    "    # Get log_likelihoods.\n",
    "    transition_scores = model.compute_transition_scores(outputs.sequences, outputs.scores, normalize_logits=True)\n",
    "    log_likelihoods = [score.item() for score in transition_scores[0]]\n",
    "\n",
    "    if len(log_likelihoods) == 1:\n",
    "        log_likelihoods = log_likelihoods\n",
    "    else:\n",
    "        log_likelihoods = log_likelihoods[:n_generated]\n",
    "\n",
    "    if len(log_likelihoods) == 0:\n",
    "        raise ValueError\n",
    "\n",
    "    hidden_states = (last_token_embedding,)\n",
    "\n",
    "    if return_latent:\n",
    "        hidden_states += (sec_last_token_embedding, last_tok_bef_gen_embedding)\n",
    "    else:\n",
    "        hidden_states += (None, None)\n",
    "\n",
    "    return_values = (sliced_answer, log_likelihoods, hidden_states)\n",
    "\n",
    "    return return_values\n",
    "\n",
    "\n",
    "def get_p_true(model, tokenizer, input_data):\n",
    "    \"\"\"\n",
    "        Get the probability of the model answering A (True) for the given input\n",
    "        \n",
    "        :param input_data:\n",
    "    \"\"\"\n",
    "\n",
    "    input_data += ' A'\n",
    "    tokenized_prompt_true = tokenizer(input_data, return_tensors='pt').to('cuda')['input_ids']\n",
    "\n",
    "    target_ids_true = tokenized_prompt_true.clone()\n",
    "    # Set all target_ids except the last one to -100.\n",
    "    target_ids_true[0, :-1] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output_true = model(tokenized_prompt_true, labels=target_ids_true)\n",
    "\n",
    "    loss_true = model_output_true.loss\n",
    "\n",
    "    return -loss_true.item()\n",
    "    \n",
    "\n",
    "def calculate_perplexity(input_data, model, tokenizer):\n",
    "    \"\"\"\n",
    "\n",
    "        :param input_data:\n",
    "        :param model:\n",
    "        :param tokenizer:\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_data = tokenizer(input_data, return_tensors='pt').to('cuda')['input_ids']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output_true = model(tokenized_data, labels=tokenized_data)\n",
    "\n",
    "    perplexity = - model_output_true.loss.item()\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bf57c",
   "metadata": {},
   "source": [
    "## P True Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deccc37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecf505254914ac0934793cf7fd13051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa26750584a9476d8b1a01a3b506e141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "squad_metric = load(\"squad_v2\")\n",
    "\n",
    "\n",
    "def p_true_construct_few_shot_prompt(\n",
    "        *, model, tokenizer, dataset, indices, prompt, brief, brief_always, make_prompt,\n",
    "        num_generations, metric, max_new_tokens, token_limit=2048):\n",
    "    \"\"\"\n",
    "        Construct few shot prompt for p_true uncertainty metric.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call model n_shots many times\n",
    "    few_shot_prompt = []\n",
    "    all_responses = dict()\n",
    "\n",
    "    for it, i in enumerate(indices):\n",
    "        prompt_candidate = []\n",
    "        example = dataset[i]\n",
    "        question = example[\"question\"]\n",
    "        context = None\n",
    "\n",
    "        if it != 0:\n",
    "            prompt_candidate += ['\\n']\n",
    "        prompt_candidate += ['Question: ' + question]\n",
    "        prompt_candidate += ['\\nBrainstormed Answers: ']\n",
    "        current_question = make_prompt(context, question, None, brief, brief_always)\n",
    "        local_prompt = prompt + current_question\n",
    "\n",
    "        responses = []\n",
    "        for j in range(num_generations + 1):\n",
    "\n",
    "            if j == 0:\n",
    "                temperature = 0.1\n",
    "            else:\n",
    "                temperature = 1.0\n",
    "\n",
    "            #response, _, _ = model.predict(local_prompt, temperature)\n",
    "            response, _, _ = model_predict(model, tokenizer, local_prompt, temperature, max_new_tokens)\n",
    "\n",
    "            responses.append(response)\n",
    "            prompt_candidate += [f'{response.strip()} \\n']\n",
    "            if j == 0:\n",
    "                # Save most likely response and compute correctness metric for it.\n",
    "                most_likely_response = response\n",
    "                is_correct = metric(response, example, model)\n",
    "                answers = [str(example['numerical_answer'])]\n",
    "                #[answer for answer in example['answers']['text']]\n",
    "\n",
    "        all_responses[i] = dict(\n",
    "            responses=responses, most_likely_response=most_likely_response,\n",
    "            is_correct=is_correct)\n",
    "\n",
    "        prompt_candidate += ['Possible answer: ' + most_likely_response + '\\n']\n",
    "        prompt_candidate += ['Is the possible answer:\\n']\n",
    "        prompt_candidate += ['A) True\\n']\n",
    "        prompt_candidate += ['B) False\\n']\n",
    "        prompt_candidate += ['The possible answer is:']\n",
    "        prompt_candidate += [' A' if is_correct else ' B']\n",
    "\n",
    "        prompt_len = len(tokenizer.encode(''.join(few_shot_prompt + prompt_candidate)))\n",
    "        # At test time, get a maximum of `num_generations * model.token_limit` extra tokens\n",
    "        # 200 buffer for question and 'Possible Answer'.\n",
    "        max_input_len = prompt_len + num_generations * max_new_tokens + 200\n",
    "\n",
    "        if max_input_len < token_limit:\n",
    "            few_shot_prompt.extend(prompt_candidate)\n",
    "        else:\n",
    "            print('Cutting of p_true prompt at length %d.', it)\n",
    "            break\n",
    "\n",
    "    return ''.join(few_shot_prompt), all_responses, it\n",
    "\n",
    "\n",
    "def calculate_p_true(\n",
    "        model, tokenizer, question, most_probable_answer, brainstormed_answers,\n",
    "        few_shot_prompt, hint=False):\n",
    "    \"\"\"\n",
    "        Calculate p_true uncertainty metric.\n",
    "    \"\"\"\n",
    "\n",
    "    if few_shot_prompt:\n",
    "        prompt = few_shot_prompt + '\\n'\n",
    "    else:\n",
    "        prompt = ''\n",
    "\n",
    "    prompt += 'Question: ' + question\n",
    "    prompt += '\\nBrainstormed Answers: '\n",
    "    for answer in brainstormed_answers + [most_probable_answer]:\n",
    "        prompt += answer.strip() + '\\n'\n",
    "    prompt += 'Possible answer: ' + most_probable_answer + '\\n'\n",
    "    if not hint:\n",
    "        prompt += 'Is the possible answer:\\n'\n",
    "        prompt += 'A) True\\n'\n",
    "        prompt += 'B) False\\n'\n",
    "        prompt += 'The possible answer is:'\n",
    "    else:\n",
    "        prompt += 'Do the brainstormed answers match the possible answer? Respond with A if they do, if they do not respond with B. Answer:'\n",
    "\n",
    "    log_prob = get_p_true(model, tokenizer, prompt)\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849e0982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#from model_utils import model_init\n",
    "#from utils import get_metric, get_reference, save\n",
    "#from dataset_prep import get_dataset, get_make_prompt, split_dataset\n",
    "\n",
    "\n",
    "def main(args, tokenizer, model):\n",
    "    experiment_details = {'args': args}\n",
    "    random.seed(10)\n",
    "\n",
    "    # todo - clean this up\n",
    "    metric = get_metric('squad')\n",
    "\n",
    "    dataset_name = 'gsm8k'\n",
    "    answerable_only = False\n",
    "    compute_p_true = True\n",
    "    brief_always = False\n",
    "    enable_brief = True\n",
    "    num_few_shot = 5\n",
    "    p_true_num_fewshot = 20\n",
    "    num_generations = 10\n",
    "    get_training_set_generations = True\n",
    "    num_samples = 100\n",
    "    get_training_set_generations_most_likely_only = True\n",
    "    temperature = 1.0\n",
    "    max_new_tokens = 50\n",
    "    compute_accuracy_at_all_temps = True\n",
    "    p_true_hint = False\n",
    "\n",
    "    running_parameters = {'brief_prompt': 'default', 'brief_always': False,\n",
    "                          'enable_brief': True, 'use_context': False}\n",
    "\n",
    "    train_dataset, validation_dataset, answerable_indices, unanswerable_indices, remaining_answerable, experiment_details = get_dataset(\n",
    "        dataset_name, experiment_details, num_few_shot, running_parameters)\n",
    "\n",
    "    if answerable_only:\n",
    "        unanswerable_indices = []\n",
    "        val_answerable, val_unanswerable = split_dataset(validation_dataset)\n",
    "        del val_unanswerable\n",
    "        validation_dataset = [validation_dataset[i] for i in val_answerable]\n",
    "\n",
    "    # Initialize model.\n",
    "    model_name = 'Mistral-7B-v0.1'\n",
    "    #tokenizer, model = model_init(model_name)\n",
    "    make_prompt = get_make_prompt(prompt_type='default', use_context=running_parameters['use_context'])\n",
    "\n",
    "    # Initialize prompt for p_true baseline.\n",
    "    if compute_p_true:\n",
    "        p_true_indices = random.sample(answerable_indices, p_true_num_fewshot)\n",
    "\n",
    "        print(p_true_indices)\n",
    "\n",
    "        remaining_answerable = list(set(remaining_answerable) - set(p_true_indices))\n",
    "        make_prompt = get_make_prompt(prompt_type='default', use_context=running_parameters['use_context'])\n",
    "\n",
    "        # todo\n",
    "        p_true_few_shot_prompt, p_true_responses, len_p_true = p_true_construct_few_shot_prompt(\n",
    "            model=model, tokenizer=tokenizer, dataset=train_dataset, indices=p_true_indices,\n",
    "            prompt=experiment_details['prompt'], brief=experiment_details['BRIEF'],\n",
    "            brief_always=brief_always and enable_brief,\n",
    "            make_prompt=make_prompt, num_generations=num_generations,\n",
    "            metric=metric, max_new_tokens=max_new_tokens)\n",
    "\n",
    "        print(p_true_few_shot_prompt, p_true_responses, len_p_true)\n",
    "\n",
    "        experiment_details['p_true_indices'] = p_true_indices\n",
    "        experiment_details['p_true_responses'] = p_true_responses\n",
    "        experiment_details['p_true_few_shot_prompt'] = p_true_few_shot_prompt\n",
    "\n",
    "    # Start answer generation.\n",
    "    for dataset_split in ['train', 'validation']:\n",
    "\n",
    "        # This will store all input data and model predictions.\n",
    "        accuracies, generations, results_dict, p_trues = [], {}, {}, []\n",
    "\n",
    "        if dataset_split == 'train':\n",
    "            if not get_training_set_generations:\n",
    "                continue\n",
    "            dataset = train_dataset\n",
    "            possible_indices = list(set(remaining_answerable) | set(unanswerable_indices))\n",
    "\n",
    "        else:\n",
    "            dataset = validation_dataset\n",
    "            possible_indices = range(0, len(dataset))\n",
    "\n",
    "        # Evaluate over random subset of the datasets.\n",
    "        try:\n",
    "            indices = random.sample(possible_indices, min(num_samples, len(dataset)))\n",
    "        except:\n",
    "            indices = random.sample(possible_indices, min(num_samples, len(dataset), len(possible_indices)))\n",
    "            \n",
    "        experiment_details[dataset_split] = {'indices': indices}\n",
    "\n",
    "        if num_samples > len(dataset):\n",
    "            print('Not enough samples in dataset. Using all %d samples.', len(dataset))\n",
    "\n",
    "        it = 0\n",
    "        for index in tqdm(indices):\n",
    "            if (it + 1 % 10) == 0:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            it += 1\n",
    "\n",
    "            # Grab example at index.\n",
    "            example = dataset[index]\n",
    "            question, context = example[\"question\"], None\n",
    "            generations[example['id']] = {'question': question, 'context': context}\n",
    "            correct_answer = example['numerical_answer']\n",
    "\n",
    "            current_input = make_prompt(\n",
    "                context, question, None, experiment_details['BRIEF'], brief_always and enable_brief)\n",
    "            local_prompt = experiment_details['prompt'] + current_input\n",
    "\n",
    "            full_responses = []\n",
    "\n",
    "            # We sample 1 low temperature answer on which we will compute the\n",
    "            # accuracy and num_generation high temperature answers which will\n",
    "            # be used to estimate the entropy.\n",
    "\n",
    "            if dataset_split == 'train' and get_training_set_generations_most_likely_only:\n",
    "                num_generations = 1\n",
    "            else:\n",
    "                num_generations = num_generations + 1\n",
    "\n",
    "            for i in range(num_generations):\n",
    "\n",
    "                # Temperature for first generation is always `0.1`.\n",
    "                temperature = 0.1 if i == 0 else temperature\n",
    "\n",
    "                predicted_answer, token_log_likelihoods, (\n",
    "                embedding, emb_last_before_gen, emb_before_eos) = model_predict(model, tokenizer, local_prompt, \n",
    "                                                                                temperature, max_new_tokens, \n",
    "                                                                                return_latent=True)\n",
    "\n",
    "                # Last token embedding\n",
    "                embedding = embedding.cpu() if embedding is not None else None\n",
    "                emb_last_before_gen = emb_last_before_gen.cpu() if emb_last_before_gen is not None else None\n",
    "                emb_before_eos = emb_before_eos.cpu() if emb_before_eos is not None else None\n",
    "\n",
    "                compute_acc = compute_accuracy_at_all_temps or (i == 0)\n",
    "                if correct_answer and compute_acc:\n",
    "                    acc = metric(predicted_answer, example, model)\n",
    "                else:\n",
    "                    acc = 0.0  # pylint: disable=invalid-name\n",
    "\n",
    "                if i == 0:\n",
    "                    accuracies.append(acc)\n",
    "                    most_likely_answer_dict = {\n",
    "                        'response': predicted_answer,\n",
    "                        'token_log_likelihoods': token_log_likelihoods,\n",
    "                        'embedding': embedding,\n",
    "                        'accuracy': acc,\n",
    "                        'emb_last_tok_before_gen': emb_last_before_gen,\n",
    "                        'emb_tok_before_eos': emb_before_eos,\n",
    "                    }\n",
    "\n",
    "                    generations[example['id']].update({\n",
    "                        'most_likely_answer': most_likely_answer_dict,\n",
    "                        'reference': get_reference(example),\n",
    "                    })\n",
    "                else:\n",
    "                    # Aggregate predictions over num_generations.\n",
    "                    full_responses.append(\n",
    "                        (predicted_answer, token_log_likelihoods, embedding, acc))\n",
    "\n",
    "            # Append all predictions for this example to `generations`.\n",
    "            generations[example['id']]['responses'] = full_responses\n",
    "\n",
    "            if compute_p_true and dataset_split == 'validation':\n",
    "                # Already compute p_true here. Avoid cost of generations in compute_uncertainty script.\n",
    "                p_true = calculate_p_true(\n",
    "                    model, tokenizer, question, most_likely_answer_dict['response'],\n",
    "                    [r[0] for r in full_responses], p_true_few_shot_prompt,\n",
    "                    hint=p_true_hint)\n",
    "                p_trues.append(p_true)\n",
    "\n",
    "        # Save generations for that split.\n",
    "        save(generations, f'{dataset_split}_generations.pkl')\n",
    "\n",
    "        # Log overall accuracy.\n",
    "        accuracy = np.mean(accuracies)\n",
    "        print(f\"Overall {dataset_split} split accuracy: {accuracy}\")\n",
    "\n",
    "        if dataset_split == 'validation':\n",
    "            if compute_p_true:\n",
    "                results_dict['uncertainty_measures'] = {\n",
    "                    'p_false': [1 - p for p in p_trues],\n",
    "                    'p_false_fixed': [1 - np.exp(p) for p in p_trues],\n",
    "                }\n",
    "\n",
    "            print(results_dict)\n",
    "            save(results_dict, 'uncertainty_measures.pkl')\n",
    "\n",
    "    save(experiment_details, 'experiment_details.pkl')\n",
    "    del model\n",
    "    del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9caf1539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2411ed3e5a46f58d8367d33370982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b7dce0588b41debe9fdb5d1c955c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525a6b23102d4c8c967e00a340e9cbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c5ca575a854709a7e919189ac12170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99eb0b88cec542d5a89a2c72c3c5b3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f20506922a406c906b36faf2cc3bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649a164f59ed4002a8c3f1743b3b18e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49f467065814df19317d948374dcc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264c068bdce24e51988b77c998ec7279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be7c593ae44e90b186a926e38e3975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f2fdad070342b3a52eec88d614b63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Mistral-7B-v0.1'\n",
    "tokenizer, model = model_init(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a924c",
   "metadata": {},
   "source": [
    "## P ik Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ea91c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6ff5c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_p_ik(train_embeddings, is_false, eval_embeddings=None, eval_is_false=None):\n",
    "    \"\"\"\n",
    "        Fit linear classifier to embeddings to predict model correctness.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Accuracy of model on Task: %f.', 1 - torch.tensor(is_false).mean())\n",
    "\n",
    "    # Convert the list of tensors to a 2D tensor.\n",
    "    train_embeddings_tensor = torch.cat(train_embeddings, dim=0)\n",
    "    embeddings_array = train_embeddings_tensor.cpu().numpy()\n",
    "\n",
    "    # Split the data into training and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings_array, is_false,\n",
    "                                                        test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit a logistic regression model.\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict deterministically and probabilistically and compute accuracy and auroc for all splits.\n",
    "    X_eval = torch.cat(eval_embeddings, dim=0).cpu().numpy()\n",
    "    y_eval = eval_is_false\n",
    "\n",
    "    Xs = [X_train, X_test, X_eval]\n",
    "    ys = [y_train, y_test, y_eval]\n",
    "    suffixes = ['train_train', 'train_test', 'eval']\n",
    "\n",
    "    metrics, y_preds_proba = {}, {}\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    fig.suptitle('Log Probabilities Predicted by p_ik when the true label is [False/True]')\n",
    "\n",
    "    for ax, suffix, X, y_true in zip(axes, suffixes, Xs, ys):\n",
    "\n",
    "        if suffix == 'eval':\n",
    "            model = LogisticRegression()\n",
    "            model.fit(embeddings_array, is_false)\n",
    "            convergence = {'n_iter': model.n_iter_[0], 'converged': (model.n_iter_ < model.max_iter)[0]}\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred_proba = model.predict_proba(X)\n",
    "        y_preds_proba[suffix] = y_pred_proba\n",
    "        acc_p_ik_train = accuracy_score(y_true, y_pred)\n",
    "        auroc_p_ik_train = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "        split_metrics = {\n",
    "            f'acc_p_ik_{suffix}': acc_p_ik_train,\n",
    "            f'auroc_p_ik_{suffix}': auroc_p_ik_train}\n",
    "        metrics.update(split_metrics)\n",
    "\n",
    "        # Plotting.\n",
    "        probabilities_of_false_points = y_pred_proba[:, 1][np.array(y_true) == 1.0]\n",
    "        probabilities_of_true_points = y_pred_proba[:, 1][np.array(y_true) == 0.0]\n",
    "        ax.hist(probabilities_of_false_points, bins=20, alpha=0.5, label='False')\n",
    "        ax.hist(probabilities_of_true_points, bins=20, alpha=0.5, label='True')\n",
    "        ax.legend(loc='upper right', title='True Label')\n",
    "        fmt = {k: f\"{v:.2f}\" for k, v in split_metrics.items()}\n",
    "        ax.set_title(f'Set: {suffix} \\n {fmt}')\n",
    "\n",
    "    # Plotting.\n",
    "    axes[0].set_ylabel('Counts')\n",
    "    axes[1].set_xlabel('Predicted Probabilities')\n",
    "    os.system('mkdir -p figures')\n",
    "    plt.savefig('figures/p_ik.png')\n",
    "    plt.savefig('figures/p_ik.pdf')\n",
    "\n",
    "    print('Metrics for p_ik classifier: %s.', metrics)\n",
    "\n",
    "    return y_preds_proba['eval'][:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1438405",
   "metadata": {},
   "source": [
    "## Semantic Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384607b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "random.seed(10)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class BaseEntailment:\n",
    "\n",
    "    def save_prediction_cache(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class EntailmentDeberta(BaseEntailment):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v2-xlarge-mnli\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"microsoft/deberta-v2-xlarge-mnli\").to(DEVICE)\n",
    "\n",
    "    def check_implication(self, text1, text2, *args, **kwargs):\n",
    "        # Deberta-mnli returns `neutral` and `entailment` classes at indices 1 and 2.\n",
    "        inputs = self.tokenizer(text1, text2, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        largest_index = torch.argmax(F.softmax(logits, dim=1))  # pylint: disable=no-member\n",
    "        prediction = largest_index.cpu().item()\n",
    "\n",
    "        if os.environ.get('DEBERTA_FULL_LOG', False):\n",
    "            print('Deberta Input: %s -> %s', text1, text2)\n",
    "            print('Deberta Prediction: %s', prediction)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "def context_entails_response(context, responses, model):\n",
    "    votes = []\n",
    "    for response in responses:\n",
    "        votes.append(model.check_implication(context, response))\n",
    "    return 2 - np.mean(votes)\n",
    "\n",
    "\n",
    "def get_semantic_ids(strings_list, model, strict_entailment=False, example=None):\n",
    "    \"\"\"Group list of predictions into semantic meaning.\"\"\"\n",
    "\n",
    "    def are_equivalent(text1, text2):\n",
    "\n",
    "        implication_1 = model.check_implication(text1, text2, example=example)\n",
    "        implication_2 = model.check_implication(text2, text1, example=example)  # pylint: disable=arguments-out-of-order\n",
    "        assert (implication_1 in [0, 1, 2]) and (implication_2 in [0, 1, 2])\n",
    "\n",
    "        if strict_entailment:\n",
    "            semantically_equivalent = (implication_1 == 2) and (implication_2 == 2)\n",
    "\n",
    "        else:\n",
    "            implications = [implication_1, implication_2]\n",
    "            # Check if none of the implications are 0 (contradiction) and not both of them are neutral.\n",
    "            semantically_equivalent = (0 not in implications) and ([1, 1] != implications)\n",
    "\n",
    "        return semantically_equivalent\n",
    "\n",
    "    # Initialise all ids with -1.\n",
    "    semantic_set_ids = [-1] * len(strings_list)\n",
    "    # Keep track of current id.\n",
    "    next_id = 0\n",
    "    for i, string1 in enumerate(strings_list):\n",
    "        # Check if string1 already has an id assigned.\n",
    "        if semantic_set_ids[i] == -1:\n",
    "            # If string1 has not been assigned an id, assign it next_id.\n",
    "            semantic_set_ids[i] = next_id\n",
    "            for j in range(i + 1, len(strings_list)):\n",
    "                # Search through all remaining strings. If they are equivalent to string1, assign them the same id.\n",
    "                if are_equivalent(string1, strings_list[j]):\n",
    "                    semantic_set_ids[j] = next_id\n",
    "            next_id += 1\n",
    "\n",
    "    assert -1 not in semantic_set_ids\n",
    "\n",
    "    return semantic_set_ids\n",
    "\n",
    "\n",
    "def logsumexp_by_id(semantic_ids, log_likelihoods, agg='sum'):\n",
    "    \"\"\"\n",
    "        Sum probabilities with the same semantic id.\n",
    "\n",
    "        Log-Sum-Exp because input and output probabilities in log space.\n",
    "    \"\"\"\n",
    "    unique_ids = sorted(list(set(semantic_ids)))\n",
    "    assert unique_ids == list(range(len(unique_ids)))\n",
    "    log_likelihood_per_semantic_id = []\n",
    "\n",
    "    for uid in unique_ids:\n",
    "        id_indices = [pos for pos, x in enumerate(semantic_ids) if x == uid]\n",
    "        id_log_likelihoods = [log_likelihoods[i] for i in id_indices]\n",
    "        if agg == 'sum':\n",
    "            logsumexp_value = np.log(np.sum(np.exp(id_log_likelihoods))) - 5.0\n",
    "        elif agg == 'sum_normalized':\n",
    "            log_lik_norm = id_log_likelihoods - np.log(np.sum(np.exp(log_likelihoods)))\n",
    "            logsumexp_value = np.log(np.sum(np.exp(log_lik_norm)))\n",
    "        elif agg == 'mean':\n",
    "            logsumexp_value = np.log(np.mean(np.exp(id_log_likelihoods)))\n",
    "        else:\n",
    "            raise ValueError\n",
    "        log_likelihood_per_semantic_id.append(logsumexp_value)\n",
    "\n",
    "    return log_likelihood_per_semantic_id\n",
    "\n",
    "\n",
    "def predictive_entropy(log_probs):\n",
    "    \"\"\"\n",
    "        Compute MC estimate of entropy.\n",
    "\n",
    "        `E[-log p(x)] ~= -1/N sum_i log p(x_i)` where i is the sequence\n",
    "        likelihood, i.e. the average token likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    entropy = -np.sum(log_probs) / len(log_probs)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def predictive_entropy_rao(log_probs):\n",
    "    entropy = -np.sum(np.exp(log_probs) * log_probs)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def cluster_assignment_entropy(semantic_ids):\n",
    "    \"\"\"\n",
    "        Estimate semantic uncertainty from how often different clusters get assigned.\n",
    "\n",
    "        We estimate the categorical distribution over cluster assignments from the\n",
    "        semantic ids. The uncertainty is then given by the entropy of that\n",
    "        distribution. This estimate does not use token likelihoods, it relies soley\n",
    "        on the cluster assignments. If probability mass is spread of between many\n",
    "        clusters, entropy is larger. If probability mass is concentrated on a few\n",
    "        clusters, entropy is small.\n",
    "\n",
    "        Input:\n",
    "            semantic_ids: List of semantic ids, e.g. [0, 1, 2, 1].\n",
    "        Output:\n",
    "            cluster_entropy: Entropy, e.g. (-p log p).sum() for p = [1/4, 2/4, 1/4].\n",
    "    \"\"\"\n",
    "\n",
    "    n_generations = len(semantic_ids)\n",
    "    counts = np.bincount(semantic_ids)\n",
    "    probabilities = counts / n_generations\n",
    "    assert np.isclose(probabilities.sum(), 1)\n",
    "    entropy = - (probabilities * np.log(probabilities)).sum()\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9917520b",
   "metadata": {},
   "source": [
    "## Computing Uncertainity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361135ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "#from model_utils import model_init\n",
    "#from utils import get_metric, save\n",
    "from collections import defaultdict\n",
    "\n",
    "# from analyze_results import analyze_run\n",
    "\n",
    "#from p_ik import get_p_ik\n",
    "#import p_true as p_true_utils\n",
    "#from dataset_prep import get_dataset, get_make_prompt\n",
    "#from semantic_entropy import (get_semantic_ids, logsumexp_by_id, predictive_entropy, predictive_entropy_rao,\n",
    "#                              cluster_assignment_entropy, context_entails_response, EntailmentDeberta)\n",
    "\n",
    "EXP_DETAILS = 'experiment_details.pkl'\n",
    "\n",
    "\n",
    "def main_uncertain(args, tokenizer, pt_model):\n",
    "    compute_predictive_entropy = True\n",
    "    compute_p_true_in_compute_stage = False\n",
    "    entailment_model = 'deberta'\n",
    "    use_all_generations = True\n",
    "    reuse_entailment_model = False\n",
    "    use_num_generations = -1\n",
    "    max_new_tokens = 50\n",
    "    recompute_accuracy = False\n",
    "    compute_context_entails_response = False\n",
    "    condition_on_question = True\n",
    "    strict_entailment = True\n",
    "    num_eval_samples = int(1e19)\n",
    "    compute_p_ik = True\n",
    "    compute_p_ik_answerable = False\n",
    "    dataset_name = 'gsm8k'\n",
    "    args_metric = 'squad_v2'\n",
    "\n",
    "    if compute_predictive_entropy:\n",
    "        print('Beginning loading for entailment model.')\n",
    "        if entailment_model == 'deberta':\n",
    "            entailment_model = EntailmentDeberta()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def restore(filename):\n",
    "        class Restored:\n",
    "            name = f'{filename}'\n",
    "\n",
    "        return Restored\n",
    "\n",
    "    experiment_details = {'args': args}\n",
    "    running_parameters = {'brief_prompt': 'default', 'brief_always': False,\n",
    "                          'enable_brief': True, 'use_context': False}\n",
    "\n",
    "    filename = 'train_generations.pkl'\n",
    "    with open(f'{filename}', \"rb\") as infile:\n",
    "        train_generations = pickle.load(infile)\n",
    "\n",
    "    if compute_p_true_in_compute_stage:\n",
    "        old_exp_file = restore(EXP_DETAILS)\n",
    "        with open(old_exp_file.name, \"rb\") as infile:\n",
    "            old_exp = pickle.load(infile)\n",
    "\n",
    "        if reuse_entailment_model:\n",
    "            pt_model = entailment_model.model\n",
    "        else:\n",
    "            model_name = 'Mistral-7B-v0.1'\n",
    "            #tokenizer, pt_model = model_init(model_name)\n",
    "\n",
    "        pt_train_dataset, pt_validation_dataset, answerable_indices, unanswerable_indices, remaining_answerable, experiment_details = get_dataset(\n",
    "            dataset_name, experiment_details, 5, running_parameters)\n",
    "\n",
    "        # Reduce num generations used in p_true if needed!\n",
    "        if not use_all_generations:\n",
    "            if use_num_generations == -1:\n",
    "                raise ValueError\n",
    "            num_gen = use_num_generations\n",
    "        else:\n",
    "            num_gen = 10\n",
    "\n",
    "        p_true_indices = random.sample(answerable_indices, 20)  # args.p_true_num_fewshot = 20\n",
    "\n",
    "        p_true_few_shot_prompt, p_true_responses, len_p_true = p_true_construct_few_shot_prompt(\n",
    "            model=pt_model,\n",
    "            tokenizer=tokenizer,\n",
    "            dataset=pt_train_dataset,\n",
    "            indices=p_true_indices,\n",
    "            prompt=old_exp['prompt'],\n",
    "            brief=old_exp['BRIEF'],\n",
    "            brief_always=old_exp['args'].brief_always and old_exp['args'].enable_brief,\n",
    "            make_prompt=get_make_prompt(old_exp['args'], use_context=running_parameters['use_context']),\n",
    "            num_generations=num_gen,\n",
    "            metric=get_metric(old_exp['args'].metric), max_new_tokens=max_new_tokens)\n",
    "\n",
    "        del p_true_responses, pt_train_dataset\n",
    "\n",
    "    if recompute_accuracy:\n",
    "        print('Recompute accuracy enabled. This does not apply to precomputed p_true!')\n",
    "        metric = get_metric(args_metric)\n",
    "\n",
    "    result_dict_pickle = restore('uncertainty_measures.pkl')\n",
    "    with open(result_dict_pickle.name, \"rb\") as infile:\n",
    "        result_dict = pickle.load(infile)\n",
    "\n",
    "    print('-----old resutl dict------------------')\n",
    "    print(result_dict)\n",
    "\n",
    "    if 'semantic_ids' not in result_dict:\n",
    "        result_dict['semantic_ids'] = []\n",
    "\n",
    "    validation_generations_pickle = restore('validation_generations.pkl')\n",
    "    with open(validation_generations_pickle.name, 'rb') as infile:\n",
    "        validation_generations = pickle.load(infile)\n",
    "\n",
    "    entropies, accuracies = defaultdict(list), defaultdict(list)\n",
    "    validation_embeddings, validation_is_true, validation_answerable = [], [], []\n",
    "    p_trues = []\n",
    "    count = 0\n",
    "\n",
    "    def is_answerable(generation):\n",
    "        return len(generation['reference']['answers']['text']) > 0\n",
    "\n",
    "    # Loop over datapoints and compute validation embeddings, accuracies and entropies.\n",
    "    for idx, tid in enumerate(validation_generations):\n",
    "        example = validation_generations[tid]\n",
    "        question = example['question']\n",
    "        context = example['context']\n",
    "        full_responses = example[\"responses\"]\n",
    "        most_likely_answer = example['most_likely_answer']\n",
    "\n",
    "        if not use_all_generations:\n",
    "            if use_num_generations == -1:\n",
    "                raise ValueError\n",
    "            responses = [fr[0] for fr in full_responses[:args.use_num_generations]]\n",
    "        else:\n",
    "            responses = [fr[0] for fr in full_responses]\n",
    "\n",
    "        if recompute_accuracy:\n",
    "            if is_answerable(example):\n",
    "                acc = metric(most_likely_answer['response'], example, None)\n",
    "            else:\n",
    "                acc = 0.0\n",
    "            validation_is_true.append(acc)\n",
    "\n",
    "        else:\n",
    "            validation_is_true.append(most_likely_answer['accuracy'])\n",
    "\n",
    "        validation_answerable.append(is_answerable(example))\n",
    "        validation_embeddings.append(most_likely_answer['embedding'])\n",
    "\n",
    "        if compute_predictive_entropy:\n",
    "            # Token log likelihoods. Shape = (n_sample, n_tokens)\n",
    "            if not use_all_generations:\n",
    "                log_liks = [r[1] for r in full_responses[:use_num_generations]]\n",
    "            else:\n",
    "                log_liks = [r[1] for r in full_responses]\n",
    "\n",
    "            for i in log_liks:\n",
    "                assert i\n",
    "\n",
    "            if compute_context_entails_response:\n",
    "                # Compute context entails answer baseline.\n",
    "                entropies['context_entails_response'].append(context_entails_response(\n",
    "                    context, responses, entailment_model))\n",
    "\n",
    "            if condition_on_question and entailment_model == 'deberta':\n",
    "                responses = [f'{question} {r}' for r in responses]\n",
    "\n",
    "            # Compute semantic ids.\n",
    "            semantic_ids = get_semantic_ids(\n",
    "                responses, model=entailment_model,\n",
    "                strict_entailment=strict_entailment, example=example)\n",
    "\n",
    "            result_dict['semantic_ids'].append(semantic_ids)\n",
    "\n",
    "            # Compute entropy from frequencies of cluster assignments.\n",
    "            entropies['cluster_assignment_entropy'].append(cluster_assignment_entropy(semantic_ids))\n",
    "\n",
    "            # Compute entropies with and without length normalized token probabilities.\n",
    "            for agg_name, agg_func in zip(['', '_sum'], [np.mean, np.sum]):\n",
    "                log_liks_agg = [agg_func(log_lik) for log_lik in log_liks]\n",
    "\n",
    "                # Compute standard entropy.\n",
    "                entropies['regular_entropy' + agg_name].append(predictive_entropy(log_liks_agg))\n",
    "\n",
    "                # Compute semantic entropies with summing and with averaging probabilities within the cluster.\n",
    "                cluster_agg_names = ['', '_sum-normalized', '_sum-normalized-rao', '_cmean']\n",
    "                cluster_aggs = ['sum', 'sum_normalized', 'sum_normalized', 'mean']\n",
    "                for cluster_agg_name, cluster_agg in zip(cluster_agg_names, cluster_aggs):\n",
    "                    log_likelihood_per_semantic_id = logsumexp_by_id(semantic_ids, log_liks_agg, agg=cluster_agg)\n",
    "                    name = 'semantic_entropy' + agg_name + cluster_agg_name\n",
    "\n",
    "                    if cluster_agg_name != '_sum-normalized-rao':\n",
    "                        pe = predictive_entropy(log_likelihood_per_semantic_id)\n",
    "                    else:\n",
    "                        pe = predictive_entropy_rao(log_likelihood_per_semantic_id)\n",
    "\n",
    "                    entropies[name].append(pe)\n",
    "\n",
    "                    # For the semantic uncertainties, we can also change the prediction, by first selecting the semantic\n",
    "                    # cluster with the highest probability, and then selecting the generation with the highest probability\n",
    "                    # within that cluster.\n",
    "                    # NOTE: nanargmax because we currently have some clusters with empty generations.\n",
    "                    max_cluster_id = np.nanargmax(log_likelihood_per_semantic_id)\n",
    "                    # Filter log_liks to max cluster.\n",
    "                    generations_in_cluster = np.array(log_liks_agg)\n",
    "                    generations_in_cluster[np.array(semantic_ids) != max_cluster_id] = -np.inf\n",
    "                    # Select generation with new max probability.\n",
    "                    max_idx_in_cluster = np.argmax(generations_in_cluster)\n",
    "                    # Accuracies for alternative generations saved at last index.\n",
    "                    accuracies[name].append(full_responses[max_idx_in_cluster][-1])\n",
    "\n",
    "            log_str = 'semantic_ids: %s, avg_token_log_likelihoods: %s, entropies: %s'\n",
    "            entropies_fmt = ', '.join([f'{i}:{j[-1]:.2f}' for i, j in entropies.items()])\n",
    "\n",
    "        if compute_p_true_in_compute_stage:\n",
    "            p_true = p_true_utils.calculate_p_true(\n",
    "                pt_model, tokenizer, question, most_likely_answer['response'],\n",
    "                responses, p_true_few_shot_prompt,\n",
    "                hint=old_exp['args'].p_true_hint)\n",
    "            p_trues.append(p_true)\n",
    "            print('p_true: %s', np.exp(p_true))\n",
    "\n",
    "        count += 1\n",
    "        if count >= num_eval_samples:\n",
    "            print('Breaking out of main loop.')\n",
    "            break\n",
    "\n",
    "    print('Accuracy on original task: %f', np.mean(validation_is_true))\n",
    "    validation_is_false = [1.0 - is_t for is_t in validation_is_true]\n",
    "    result_dict['validation_is_false'] = validation_is_false\n",
    "\n",
    "    validation_unanswerable = [1.0 - is_a for is_a in validation_answerable]\n",
    "    result_dict['validation_unanswerable'] = validation_unanswerable\n",
    "    print('Unanswerable prop on validation: %f', np.mean(validation_unanswerable))\n",
    "\n",
    "    if 'uncertainty_measures' not in result_dict:\n",
    "        result_dict['uncertainty_measures'] = dict()\n",
    "\n",
    "    if compute_predictive_entropy:\n",
    "        result_dict['uncertainty_measures'].update(entropies)\n",
    "        accuracies_mean = {k: np.mean(v) for k, v in accuracies.items()}\n",
    "        print('Accuracy on original task from cluster-based generations: %s', accuracies_mean)\n",
    "\n",
    "        result_dict['alt_validation_accuracies_mean'] = accuracies_mean\n",
    "        result_dict['alt_validation_is_false'] = {k: [1 - vi for vi in v] for k, v in accuracies.items()}\n",
    "\n",
    "    if compute_p_ik or compute_p_ik_answerable:\n",
    "        # Assemble training data for embedding classification.\n",
    "        train_is_true, train_embeddings, train_answerable = [], [], []\n",
    "        for tid in train_generations:\n",
    "            most_likely_answer = train_generations[tid]['most_likely_answer']\n",
    "            train_embeddings.append(most_likely_answer['embedding'])\n",
    "            train_is_true.append(most_likely_answer['accuracy'])\n",
    "            train_answerable.append(is_answerable(train_generations[tid]))\n",
    "        train_is_false = [0.0 if is_t else 1.0 for is_t in train_is_true]\n",
    "        train_unanswerable = [0.0 if is_t else 1.0 for is_t in train_answerable]\n",
    "        print('Unanswerable prop on p_ik training: %f', np.mean(train_unanswerable))\n",
    "\n",
    "    if compute_p_ik:\n",
    "        print('Starting training p_ik on train embeddings.')\n",
    "        # Train classifier of correct/incorrect.\n",
    "        p_ik_predictions = get_p_ik(\n",
    "            train_embeddings=train_embeddings, is_false=train_is_false,\n",
    "            eval_embeddings=validation_embeddings, eval_is_false=validation_is_false)\n",
    "        result_dict['uncertainty_measures']['p_ik'] = p_ik_predictions\n",
    "        print('Finished training p_ik on train embeddings.')\n",
    "\n",
    "    if compute_p_ik_answerable:\n",
    "        # Train classifier of answerable/unanswerable:\n",
    "        p_ik_predictions = get_p_ik(\n",
    "            train_embeddings=train_embeddings, is_false=train_unanswerable,\n",
    "            eval_embeddings=validation_embeddings, eval_is_false=validation_unanswerable)\n",
    "        result_dict['uncertainty_measures']['p_ik_unanswerable'] = p_ik_predictions\n",
    "\n",
    "    if compute_p_true_in_compute_stage:\n",
    "        result_dict['uncertainty_measures']['p_false'] = [1 - p for p in p_trues]\n",
    "        result_dict['uncertainty_measures']['p_false_fixed'] = [1 - np.exp(p) for p in p_trues]\n",
    "\n",
    "    save(result_dict, 'uncertainty_measures_se_calc.pkl')\n",
    "    print('------results_dict----------------')\n",
    "    print(result_dict)\n",
    "\n",
    "    if compute_predictive_entropy:\n",
    "        entailment_model.save_prediction_cache()\n",
    "\n",
    "    # if args.analyze_run:\n",
    "    #    analyze_run(wandb.run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8328d19b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 105, 236, 416, 251, 421, 142, 334, 415, 82, 17, 266, 250, 167, 38, 127, 487, 381, 184, 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutting of p_true prompt at length %d. 7\n",
      "Question: Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "Brainstormed Answers: 12 \n",
      "6 \n",
      "9 \n",
      "8 \n",
      "8 \n",
      "8 \n",
      "13.8 \n",
      "8 \n",
      "10 \n",
      "224 \n",
      "8 \n",
      "Possible answer: 12\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Paddington has 40 more goats than Washington. If Washington has 140 goats, how many goats do they have in total?\n",
      "Brainstormed Answers: 180 \n",
      "180 \n",
      "70 \n",
      "90 \n",
      "180 \n",
      "180 \n",
      "180 \n",
      "180 \n",
      "180 \n",
      "180 \n",
      "240 \n",
      "Possible answer: 180\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Jake has $5000. He spends $2800 on a new motorcycle, and then spends half of what's left on a concert ticket. Jake then loses a fourth of what he has left. How much money does he have left?\n",
      "Brainstormed Answers: 1000 \n",
      "1400 \n",
      "400 \n",
      "780 \n",
      "280 \n",
      "1100 \n",
      "360 \n",
      "264 \n",
      "760 \n",
      "480 \n",
      "1000 \n",
      "Possible answer: 1000\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: In mid-May, the river flowing through Moreland is five feet deep. By mid-June, the river is 10 feet deeper than mid-May. By mid-July, the river is three times deeper than mid-June. How many feet deep is the river by mid-July?\n",
      "Brainstormed Answers: 20 \n",
      "25 \n",
      "10 \n",
      "20 \n",
      "25 \n",
      "20 \n",
      "20 \n",
      "30 \n",
      "8 feet \n",
      "20 \n",
      "12 \n",
      "Possible answer: 20\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: One pie costs $4 for a piece. Each pie is having 3 pieces. During one hour the bakery can make 12 pies. Creating one pie costs the bakery $0.5. Considering the bakery would be able to sell all pie pieces, how much money would it make?\n",
      "Brainstormed Answers: 12 \n",
      "$24 \n",
      "48 \n",
      "$18 \n",
      "4.4 \n",
      "7.2\n",
      "\n",
      "## Share this\n",
      "\n",
      "Questions answered: 65\n",
      "\n",
      "Have a comment, suggestion or a question? leave a comment and I'll try answering it and adding it to the list below.\n",
      "\n",
      "#### \n",
      "387.5 \n",
      "$25 \n",
      "7.24 USD \n",
      "54 \n",
      "60 \n",
      "Possible answer: 12\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Mrs. Wilsborough saved $500 to buy concert tickets for her family. She bought 2 VIP tickets at $100 each and 3 regular tickets at $50 each. How much of her savings does Mrs. Wilsborough have after she buys the tickets?\n",
      "Brainstormed Answers: $350 \n",
      "350 \n",
      "$60 \n",
      "350 \n",
      "$50 \n",
      "350 \n",
      "$300 \n",
      "$150 \n",
      "$300 \n",
      "$350 \n",
      "350 \n",
      "Possible answer: $350\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: A cleaning company produces two sanitizer sprays. One spray kills 50% of germs, and another spray kills 25% of germs. However, 5% of the germs they kill are the same ones. What percentage of germs would be left after using both sanitizer sprays together?\n",
      "Brainstormed Answers: 10 \n",
      "70 \n",
      "80% \n",
      "15%\n",
      "\n",
      "You can also ask your Question to us by mentioning it in the comments section below! \n",
      "39% \n",
      "30 \n",
      "28% \n",
      "55 \n",
      "20 \n",
      "50 \n",
      "100% \n",
      "Possible answer: 10\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B {7: {'responses': ['12', '6', '9', '8', '8', '8', '13.8', '8', '10', '224', '8'], 'most_likely_response': '12', 'is_correct': 0.0}, 105: {'responses': ['180', '180', '70', '90', '180', '180', '180', '180', '180', '180', '240'], 'most_likely_response': '180', 'is_correct': 0.0}, 236: {'responses': ['1000', '1400', '400', '780', '280', '1100', '360', '264', '760', '480', '1000'], 'most_likely_response': '1000', 'is_correct': 0.0}, 416: {'responses': ['20', '25', '10', '20', '25', '20', '20', '30', '8 feet', '20', '12'], 'most_likely_response': '20', 'is_correct': 0.0}, 251: {'responses': ['12', '$24', '48', '$18', '4.4', \"7.2\\n\\n## Share this\\n\\nQuestions answered: 65\\n\\nHave a comment, suggestion or a question? leave a comment and I'll try answering it and adding it to the list below.\\n\\n####\", '387.5', '$25', '7.24 USD', '54', '60'], 'most_likely_response': '12', 'is_correct': 0.0}, 421: {'responses': ['$350', '350', '$60', '350', '$50', '350', '$300', '$150', '$300', '$350', '350'], 'most_likely_response': '$350', 'is_correct': 0.0}, 142: {'responses': ['10', '70', '80%', '15%\\n\\nYou can also ask your Question to us by mentioning it in the comments section below!', '39%', '30', '28%', '55', '20', '50', '100%'], 'most_likely_response': '10', 'is_correct': 0.0}, 334: {'responses': ['12', '7', '$9.60', '18', '$23', '7', '58', '11', '1080', '25', '$10.00'], 'most_likely_response': '12', 'is_correct': 0.0}} 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                   | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  2%|█▌                                                                         | 1/50 [00:00<00:39,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  4%|███                                                                        | 2/50 [00:01<00:37,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  6%|████▌                                                                      | 3/50 [00:02<00:37,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  8%|██████                                                                     | 4/50 [00:03<00:36,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 10%|███████▌                                                                   | 5/50 [00:04<00:36,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 12%|█████████                                                                  | 6/50 [00:04<00:36,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 14%|██████████▌                                                                | 7/50 [00:05<00:35,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 16%|████████████                                                               | 8/50 [00:06<00:34,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 18%|█████████████▌                                                             | 9/50 [00:07<00:33,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 20%|██████████████▊                                                           | 10/50 [00:08<00:32,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 22%|████████████████▎                                                         | 11/50 [00:08<00:31,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 24%|█████████████████▊                                                        | 12/50 [00:09<00:30,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 26%|███████████████████▏                                                      | 13/50 [00:10<00:29,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 28%|████████████████████▋                                                     | 14/50 [00:11<00:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 30%|██████████████████████▏                                                   | 15/50 [00:12<00:28,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 32%|███████████████████████▋                                                  | 16/50 [00:12<00:27,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 34%|█████████████████████████▏                                                | 17/50 [00:13<00:26,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 36%|██████████████████████████▋                                               | 18/50 [00:14<00:26,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 38%|████████████████████████████                                              | 19/50 [00:15<00:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 40%|█████████████████████████████▌                                            | 20/50 [00:16<00:24,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 42%|███████████████████████████████                                           | 21/50 [00:17<00:23,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 44%|████████████████████████████████▌                                         | 22/50 [00:17<00:21,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 46%|██████████████████████████████████                                        | 23/50 [00:18<00:21,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 48%|███████████████████████████████████▌                                      | 24/50 [00:19<00:20,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 50%|█████████████████████████████████████                                     | 25/50 [00:20<00:19,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 52%|██████████████████████████████████████▍                                   | 26/50 [00:20<00:19,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 54%|███████████████████████████████████████▉                                  | 27/50 [00:21<00:18,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 56%|█████████████████████████████████████████▍                                | 28/50 [00:22<00:17,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 58%|██████████████████████████████████████████▉                               | 29/50 [00:23<00:16,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 60%|████████████████████████████████████████████▍                             | 30/50 [00:24<00:15,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 62%|█████████████████████████████████████████████▉                            | 31/50 [00:24<00:15,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 64%|███████████████████████████████████████████████▎                          | 32/50 [00:25<00:14,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 66%|████████████████████████████████████████████████▊                         | 33/50 [00:26<00:13,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 68%|██████████████████████████████████████████████████▎                       | 34/50 [00:27<00:13,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 70%|███████████████████████████████████████████████████▊                      | 35/50 [00:28<00:12,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 72%|█████████████████████████████████████████████████████▎                    | 36/50 [00:28<00:11,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 74%|██████████████████████████████████████████████████████▊                   | 37/50 [00:29<00:10,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 76%|████████████████████████████████████████████████████████▏                 | 38/50 [00:30<00:09,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 78%|█████████████████████████████████████████████████████████▋                | 39/50 [00:31<00:09,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 80%|███████████████████████████████████████████████████████████▏              | 40/50 [00:32<00:08,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 82%|████████████████████████████████████████████████████████████▋             | 41/50 [00:33<00:07,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 84%|██████████████████████████████████████████████████████████████▏           | 42/50 [00:33<00:06,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 86%|███████████████████████████████████████████████████████████████▋          | 43/50 [00:34<00:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 88%|█████████████████████████████████████████████████████████████████         | 44/50 [00:35<00:04,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [00:36<00:04,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 92%|████████████████████████████████████████████████████████████████████      | 46/50 [00:37<00:03,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [00:37<00:02,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 96%|███████████████████████████████████████████████████████████████████████   | 48/50 [00:38<00:01,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [00:39<00:00,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.24it/s]\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall train split accuracy: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                   | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  2%|█▌                                                                         | 1/50 [00:02<02:20,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  4%|███                                                                        | 2/50 [00:07<03:04,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  6%|████▌                                                                      | 3/50 [00:12<03:19,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "  8%|██████                                                                     | 4/50 [00:17<03:43,  4.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 10%|███████▌                                                                   | 5/50 [00:24<04:00,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 12%|█████████                                                                  | 6/50 [00:31<04:22,  5.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 14%|██████████▌                                                                | 7/50 [00:38<04:37,  6.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 16%|████████████                                                               | 8/50 [00:46<04:55,  7.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 18%|█████████████▌                                                             | 9/50 [00:56<05:15,  7.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 20%|██████████████▊                                                           | 10/50 [01:06<05:36,  8.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 22%|████████████████▎                                                         | 11/50 [01:16<05:47,  8.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 24%|█████████████████▊                                                        | 12/50 [01:27<06:02,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 26%|███████████████████▏                                                      | 13/50 [01:41<06:42, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 28%|████████████████████▋                                                     | 14/50 [01:55<07:07, 11.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 30%|██████████████████████▏                                                   | 15/50 [02:09<07:23, 12.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 32%|███████████████████████▋                                                  | 16/50 [02:26<07:51, 13.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 34%|█████████████████████████▏                                                | 17/50 [02:43<08:12, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 36%|██████████████████████████▋                                               | 18/50 [03:00<08:15, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 38%|████████████████████████████                                              | 19/50 [03:18<08:24, 16.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 40%|█████████████████████████████▌                                            | 20/50 [03:40<08:57, 17.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 42%|███████████████████████████████                                           | 21/50 [03:59<08:46, 18.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 44%|████████████████████████████████▌                                         | 22/50 [04:18<08:41, 18.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 46%|██████████████████████████████████                                        | 23/50 [04:39<08:38, 19.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 48%|███████████████████████████████████▌                                      | 24/50 [04:58<08:21, 19.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 50%|█████████████████████████████████████                                     | 25/50 [05:25<08:53, 21.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 52%|██████████████████████████████████████▍                                   | 26/50 [05:49<08:51, 22.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 54%|███████████████████████████████████████▉                                  | 27/50 [06:11<08:27, 22.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 56%|█████████████████████████████████████████▍                                | 28/50 [06:37<08:33, 23.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 58%|██████████████████████████████████████████▉                               | 29/50 [07:02<08:20, 23.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 60%|████████████████████████████████████████████▍                             | 30/50 [07:31<08:30, 25.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 62%|█████████████████████████████████████████████▉                            | 31/50 [07:59<08:17, 26.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 64%|███████████████████████████████████████████████▎                          | 32/50 [08:28<08:08, 27.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 66%|████████████████████████████████████████████████▊                         | 33/50 [08:59<07:57, 28.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 68%|██████████████████████████████████████████████████▎                       | 34/50 [09:30<07:43, 28.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 70%|███████████████████████████████████████████████████▊                      | 35/50 [10:06<07:48, 31.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 72%|█████████████████████████████████████████████████████▎                    | 36/50 [10:39<07:25, 31.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 74%|██████████████████████████████████████████████████████▊                   | 37/50 [11:13<07:01, 32.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 76%|████████████████████████████████████████████████████████▏                 | 38/50 [11:45<06:27, 32.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 78%|█████████████████████████████████████████████████████████▋                | 39/50 [12:18<05:56, 32.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 80%|███████████████████████████████████████████████████████████▏              | 40/50 [12:52<05:29, 32.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 82%|████████████████████████████████████████████████████████████▋             | 41/50 [13:27<05:01, 33.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 84%|██████████████████████████████████████████████████████████████▏           | 42/50 [14:04<04:36, 34.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 86%|███████████████████████████████████████████████████████████████▋          | 43/50 [14:47<04:19, 37.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 88%|█████████████████████████████████████████████████████████████████         | 44/50 [15:26<03:45, 37.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████▌       | 45/50 [16:07<03:13, 38.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 92%|████████████████████████████████████████████████████████████████████      | 46/50 [16:48<02:37, 39.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████▌    | 47/50 [17:32<02:01, 40.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 96%|███████████████████████████████████████████████████████████████████████   | 48/50 [18:18<01:24, 42.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████▌ | 49/50 [18:58<00:41, 41.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [19:40<00:00, 41.66s/it]\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [19:40<00:00, 23.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation split accuracy: 0.16\n"
     ]
    }
   ],
   "source": [
    "args = dict()\n",
    "args['temperature'] = 1.0\n",
    "args['num_samples'] = 50\n",
    "args['metric'] = 'squad_v2'\n",
    "args['enable_brief'] = True\n",
    "\n",
    "args['p_true_hint'] = False\n",
    "args['enable_brief'] = True\n",
    "args['use_context'] = False\n",
    "args['max_new_tokens'] = 50\n",
    "\n",
    "args['brief_always'] = False\n",
    "args['brief_always'] = False\n",
    "args['num_generations'] = 10\n",
    "\n",
    "args['compute_p_true'] = True\n",
    "args['dataset_name'] = 'gsm8k'\n",
    "args['answerable_only'] = False\n",
    "args['p_true_num_fewshot'] = 20\n",
    "args['brief_prompt'] = 'default'\n",
    "\n",
    "args['get_training_set_generations'] = True\n",
    "args['compute_accuracy_at_all_temps'] = True\n",
    "args['get_training_set_generations_most_likely_only'] = True\n",
    "\n",
    "main(args, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b16683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 422, 947, 1665, 1006, 1686, 568, 1338, 1660, 328, 70, 1066, 1003, 671, 155, 511, 1950, 1951, 1526, 739]\n",
      "Cutting of p_true prompt at length %d. 8\n",
      "Question: Ann, Bill, Cate, and Dale each buy personal pan pizzas cut into 4 pieces. If Bill and Dale eat 50% of their pizzas and Ann and Cate eat 75% of the pizzas, how many pizza pieces are left uneaten?\n",
      "Brainstormed Answers: 16 \n",
      "7 \n",
      "8 \n",
      "40\n",
      "\n",
      "If you still have any questions or suggestions feel free to leave us a comment below.\n",
      "Also Read How To Make Your Math Tutor Your Friend\n",
      "\n",
      "Do you know anyone who is looking for a math tutor? \n",
      "8 \n",
      "7 \n",
      "4 \n",
      "10 \n",
      "8 \n",
      "3 \n",
      "4 \n",
      "Possible answer: 16\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Bryan works as a social media account manager. He does marketing posts, advertisement posts, and customer outreach posts. His client has him spend four hours on customer outreach posts and half that time on advertisement posts each day. Bryan works eight hours a day. How much time in hours each day does he spend on marketing posts?\n",
      "Brainstormed Answers: 4 \n",
      "4\n",
      "\n",
      "Answer the following question as briefly as possible. \n",
      "3 \n",
      "8 \n",
      "1 \n",
      "9.6 \n",
      "56 \n",
      "5 \n",
      "4 \n",
      "8 \n",
      "2 \n",
      "Possible answer: 4\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Jason goes to the library 4 times more often than William goes. If William goes 2 times per week to the library, how many times does Jason go to the library in 4 weeks?\n",
      "Brainstormed Answers: 16 \n",
      "16 \n",
      "16 \n",
      "12 \n",
      "64 \n",
      "24 \n",
      "8 \n",
      "8 \n",
      "8 \n",
      "16 \n",
      "6 \n",
      "Possible answer: 16\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: Calvin buys a pack of chips, for $0.50, from the vending machine at lunch, 5 days a week. After 4 weeks, how much money has Calvin spent on chips?\n",
      "Brainstormed Answers: 10 \n",
      "16 \n",
      "10 \n",
      "$2 \n",
      "$5 \n",
      "20 \n",
      "$10 \n",
      "2.0 \n",
      "2050 cents \n",
      "25 \n",
      "$20 \n",
      "Possible answer: 10\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: A\n",
      "Question: Rajesh walked 10 kilometers less than 4 times the distance that Hiro walked. Together they walked 25 kilometers. How many kilometers did Rajesh walk?\n",
      "Brainstormed Answers: 10 \n",
      "9 \n",
      "15 \n",
      "50 \n",
      "10 \n",
      "40 \n",
      "5 \n",
      "25 \n",
      "5 \n",
      "8.5\n",
      "If you have any doubt, contact us here. We are available 24/7 to serve you. \n",
      "10 \n",
      "Possible answer: 10\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: A farmer hires small trucks to transport his lemons to the markets. The load on a truck may not be more than 900 kilograms. One bag of lemons has a mass of 8 kilograms. If there are 100 bags of lemons, how many more kilograms can still be loaded into the truck?\n",
      "Brainstormed Answers: 800 \n",
      "680 \n",
      "720 kg \n",
      "820 \n",
      "20 \n",
      "840 \n",
      "820 \n",
      "2300 \n",
      "36 \n",
      "120 \n",
      "80 \n",
      "Possible answer: 800\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: At a gym, the blue weights are 2 pounds each, and the green weights are 3 pounds each. Harry put 4 blue weights and 5 green weights onto a metal bar. The bar itself weighs 2 pounds. What is the total amount of weight, in pounds, of Harry's custom creation?\n",
      "Brainstormed Answers: 17 \n",
      "20 \n",
      "30 \n",
      "30 \n",
      "20 \n",
      "19 \n",
      "17 \n",
      "12 \n",
      "4 \n",
      "21 \n",
      "20 pounds \n",
      "Possible answer: 17\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: B\n",
      "Question: A plumber bought 10 meters of copper and 5 more meters of plastic pipe. If each meter cost $4, how much did the plumber spent on the copper and plastic pipe?\n",
      "Brainstormed Answers: 100 \n",
      "40 \n",
      " \n",
      "80 \n",
      "120 \n",
      "60 \n",
      "$60 \n",
      "196 \n",
      "$88 \n",
      "52 \n",
      "50$\n",
      "\n",
      "Related\n",
      "\n",
      "### More about\n",
      "\n",
      "Word problem answers are available in this page or from below search.\n",
      "\n",
      "### You may also like :\n",
      "\n",
      "Welcome to the website. Here you can find answers to \n",
      "Possible answer: 100\n",
      "Is the possible answer:\n",
      "A) True\n",
      "B) False\n",
      "The possible answer is: A {30: {'responses': ['16', '7', '8', '40\\n\\nIf you still have any questions or suggestions feel free to leave us a comment below.\\nAlso Read How To Make Your Math Tutor Your Friend\\n\\nDo you know anyone who is looking for a math tutor?', '8', '7', '4', '10', '8', '3', '4'], 'most_likely_response': '16', 'is_correct': 0.0}, 422: {'responses': ['4', '4\\n\\nAnswer the following question as briefly as possible.', '3', '8', '1', '9.6', '56', '5', '4', '8', '2'], 'most_likely_response': '4', 'is_correct': 0.0}, 947: {'responses': ['16', '16', '16', '12', '64', '24', '8', '8', '8', '16', '6'], 'most_likely_response': '16', 'is_correct': 0.0}, 1665: {'responses': ['10', '16', '10', '$2', '$5', '20', '$10', '2.0', '2050 cents', '25', '$20'], 'most_likely_response': '10', 'is_correct': 1.0}, 1006: {'responses': ['10', '9', '15', '50', '10', '40', '5', '25', '5', '8.5\\nIf you have any doubt, contact us here. We are available 24/7 to serve you.', '10'], 'most_likely_response': '10', 'is_correct': 0.0}, 1686: {'responses': ['800', '680', '720 kg', '820', '20', '840', '820', '2300', '36', '120', '80'], 'most_likely_response': '800', 'is_correct': 0.0}, 568: {'responses': ['17', '20', '30', '30', '20', '19', '17', '12', '4', '21', '20 pounds'], 'most_likely_response': '17', 'is_correct': 0.0}, 1338: {'responses': ['100', '40', '', '80', '120', '60', '$60', '196', '$88', '52', '50$\\n\\nRelated\\n\\n### More about\\n\\nWord problem answers are available in this page or from below search.\\n\\n### You may also like :\\n\\nWelcome to the website. Here you can find answers to'], 'most_likely_response': '100', 'is_correct': 1.0}, 1660: {'responses': ['1998', '15 or 6', '16', '1994', '1999', '1997', '1981', '1998', '18', '17 years ago', '1990'], 'most_likely_response': '1998', 'is_correct': 0.0}} 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                  | 0/100 [00:00<?, ?it/s]\r",
      "  1%|▋                                                                         | 1/100 [00:01<03:07,  1.90s/it]\r",
      "  2%|█▍                                                                        | 2/100 [00:03<03:11,  1.96s/it]\r",
      "  3%|██▏                                                                       | 3/100 [00:05<03:06,  1.92s/it]\r",
      "  4%|██▉                                                                       | 4/100 [00:07<03:05,  1.94s/it]\r",
      "  5%|███▋                                                                      | 5/100 [00:09<03:04,  1.94s/it]\r",
      "  6%|████▍                                                                     | 6/100 [00:11<03:02,  1.95s/it]\r",
      "  7%|█████▏                                                                    | 7/100 [00:13<03:03,  1.97s/it]\r",
      "  8%|█████▉                                                                    | 8/100 [00:15<03:07,  2.03s/it]\r",
      "  9%|██████▋                                                                   | 9/100 [00:17<03:03,  2.02s/it]\r",
      " 10%|███████▎                                                                 | 10/100 [00:20<03:06,  2.08s/it]\r",
      " 11%|████████                                                                 | 11/100 [00:22<03:03,  2.06s/it]\r",
      " 12%|████████▊                                                                | 12/100 [00:24<03:00,  2.05s/it]\r",
      " 13%|█████████▍                                                               | 13/100 [00:26<02:58,  2.05s/it]\r",
      " 14%|██████████▏                                                              | 14/100 [00:28<02:56,  2.05s/it]\r",
      " 15%|██████████▉                                                              | 15/100 [00:30<02:57,  2.09s/it]\r",
      " 16%|███████████▋                                                             | 16/100 [00:32<02:57,  2.12s/it]\r",
      " 17%|████████████▍                                                            | 17/100 [00:34<02:55,  2.12s/it]\r",
      " 18%|█████████████▏                                                           | 18/100 [00:36<02:54,  2.13s/it]\r",
      " 19%|█████████████▊                                                           | 19/100 [00:39<02:55,  2.17s/it]\r",
      " 20%|██████████████▌                                                          | 20/100 [00:41<02:52,  2.16s/it]\r",
      " 21%|███████████████▎                                                         | 21/100 [00:43<02:49,  2.15s/it]\r",
      " 22%|████████████████                                                         | 22/100 [00:45<02:47,  2.14s/it]\r",
      " 23%|████████████████▊                                                        | 23/100 [00:47<02:48,  2.19s/it]\r",
      " 24%|█████████████████▌                                                       | 24/100 [00:49<02:40,  2.12s/it]\r",
      " 25%|██████████████████▎                                                      | 25/100 [00:51<02:36,  2.08s/it]\r",
      " 26%|██████████████████▉                                                      | 26/100 [00:53<02:33,  2.07s/it]\r",
      " 27%|███████████████████▋                                                     | 27/100 [00:55<02:29,  2.05s/it]\r",
      " 28%|████████████████████▍                                                    | 28/100 [00:57<02:25,  2.02s/it]\r",
      " 29%|█████████████████████▏                                                   | 29/100 [00:59<02:27,  2.08s/it]\r",
      " 30%|█████████████████████▉                                                   | 30/100 [01:01<02:25,  2.07s/it]\r",
      " 31%|██████████████████████▋                                                  | 31/100 [01:03<02:21,  2.05s/it]\r",
      " 32%|███████████████████████▎                                                 | 32/100 [01:05<02:16,  2.01s/it]\r",
      " 33%|████████████████████████                                                 | 33/100 [01:07<02:13,  1.99s/it]\r",
      " 34%|████████████████████████▊                                                | 34/100 [01:09<02:10,  1.98s/it]\r",
      " 35%|█████████████████████████▌                                               | 35/100 [01:11<02:10,  2.00s/it]\r",
      " 36%|██████████████████████████▎                                              | 36/100 [01:13<02:06,  1.97s/it]\r",
      " 37%|███████████████████████████                                              | 37/100 [01:15<02:04,  1.97s/it]\r",
      " 38%|███████████████████████████▋                                             | 38/100 [01:17<02:04,  2.00s/it]\r",
      " 39%|████████████████████████████▍                                            | 39/100 [01:19<02:01,  2.00s/it]\r",
      " 40%|█████████████████████████████▏                                           | 40/100 [01:21<01:59,  1.99s/it]\r",
      " 41%|█████████████████████████████▉                                           | 41/100 [01:23<01:57,  2.00s/it]\r",
      " 42%|██████████████████████████████▋                                          | 42/100 [01:25<01:55,  1.99s/it]\r",
      " 43%|███████████████████████████████▍                                         | 43/100 [01:27<01:54,  2.01s/it]\r",
      " 44%|████████████████████████████████                                         | 44/100 [01:29<01:50,  1.97s/it]\r",
      " 45%|████████████████████████████████▊                                        | 45/100 [01:31<01:47,  1.96s/it]\r",
      " 46%|█████████████████████████████████▌                                       | 46/100 [01:33<01:43,  1.92s/it]\r",
      " 47%|██████████████████████████████████▎                                      | 47/100 [01:35<01:42,  1.93s/it]\r",
      " 48%|███████████████████████████████████                                      | 48/100 [01:37<01:40,  1.93s/it]\r",
      " 49%|███████████████████████████████████▊                                     | 49/100 [01:39<01:39,  1.95s/it]\r",
      " 50%|████████████████████████████████████▌                                    | 50/100 [01:41<01:38,  1.96s/it]\r",
      " 51%|█████████████████████████████████████▏                                   | 51/100 [01:43<01:35,  1.95s/it]\r",
      " 52%|█████████████████████████████████████▉                                   | 52/100 [01:45<01:33,  1.95s/it]\r",
      " 53%|██████████████████████████████████████▋                                  | 53/100 [01:47<01:31,  1.94s/it]\r",
      " 54%|███████████████████████████████████████▍                                 | 54/100 [01:49<01:31,  2.00s/it]\r",
      " 55%|████████████████████████████████████████▏                                | 55/100 [01:51<01:28,  1.97s/it]\r",
      " 56%|████████████████████████████████████████▉                                | 56/100 [01:53<01:26,  1.96s/it]\r",
      " 57%|█████████████████████████████████████████▌                               | 57/100 [01:55<01:24,  1.97s/it]\r",
      " 58%|██████████████████████████████████████████▎                              | 58/100 [01:57<01:22,  1.96s/it]\r",
      " 59%|███████████████████████████████████████████                              | 59/100 [01:58<01:19,  1.94s/it]\r",
      " 60%|███████████████████████████████████████████▊                             | 60/100 [02:00<01:17,  1.93s/it]\r",
      " 61%|████████████████████████████████████████████▌                            | 61/100 [02:02<01:16,  1.97s/it]\r",
      " 62%|█████████████████████████████████████████████▎                           | 62/100 [02:04<01:13,  1.94s/it]\r",
      " 63%|█████████████████████████████████████████████▉                           | 63/100 [02:06<01:11,  1.94s/it]\r",
      " 64%|██████████████████████████████████████████████▋                          | 64/100 [02:08<01:10,  1.95s/it]\r",
      " 65%|███████████████████████████████████████████████▍                         | 65/100 [02:10<01:08,  1.95s/it]\r",
      " 66%|████████████████████████████████████████████████▏                        | 66/100 [02:12<01:06,  1.96s/it]\r",
      " 67%|████████████████████████████████████████████████▉                        | 67/100 [02:14<01:08,  2.08s/it]\r",
      " 68%|█████████████████████████████████████████████████▋                       | 68/100 [02:16<01:04,  2.02s/it]\r",
      " 69%|██████████████████████████████████████████████████▎                      | 69/100 [02:18<01:01,  1.99s/it]\r",
      " 70%|███████████████████████████████████████████████████                      | 70/100 [02:20<00:59,  1.98s/it]\r",
      " 71%|███████████████████████████████████████████████████▊                     | 71/100 [02:22<00:56,  1.95s/it]\r",
      " 72%|████████████████████████████████████████████████████▌                    | 72/100 [02:24<00:54,  1.96s/it]\r",
      " 73%|█████████████████████████████████████████████████████▎                   | 73/100 [02:26<00:52,  1.93s/it]\r",
      " 74%|██████████████████████████████████████████████████████                   | 74/100 [02:28<00:49,  1.91s/it]\r",
      " 75%|██████████████████████████████████████████████████████▊                  | 75/100 [02:30<00:47,  1.89s/it]\r",
      " 76%|███████████████████████████████████████████████████████▍                 | 76/100 [02:31<00:45,  1.88s/it]\r",
      " 77%|████████████████████████████████████████████████████████▏                | 77/100 [02:33<00:42,  1.86s/it]\r",
      " 78%|████████████████████████████████████████████████████████▉                | 78/100 [02:35<00:40,  1.86s/it]\r",
      " 79%|█████████████████████████████████████████████████████████▋               | 79/100 [02:37<00:39,  1.90s/it]\r",
      " 80%|██████████████████████████████████████████████████████████▍              | 80/100 [02:39<00:38,  1.94s/it]\r",
      " 81%|███████████████████████████████████████████████████████████▏             | 81/100 [02:41<00:36,  1.92s/it]\r",
      " 82%|███████████████████████████████████████████████████████████▊             | 82/100 [02:43<00:34,  1.92s/it]\r",
      " 83%|████████████████████████████████████████████████████████████▌            | 83/100 [02:45<00:32,  1.92s/it]\r",
      " 84%|█████████████████████████████████████████████████████████████▎           | 84/100 [02:47<00:30,  1.93s/it]\r",
      " 85%|██████████████████████████████████████████████████████████████           | 85/100 [02:49<00:28,  1.93s/it]\r",
      " 86%|██████████████████████████████████████████████████████████████▊          | 86/100 [02:51<00:26,  1.91s/it]\r",
      " 87%|███████████████████████████████████████████████████████████████▌         | 87/100 [02:53<00:24,  1.91s/it]\r",
      " 88%|████████████████████████████████████████████████████████████████▏        | 88/100 [02:55<00:23,  1.92s/it]\r",
      " 89%|████████████████████████████████████████████████████████████████▉        | 89/100 [02:56<00:21,  1.93s/it]\r",
      " 90%|█████████████████████████████████████████████████████████████████▋       | 90/100 [02:58<00:19,  1.92s/it]\r",
      " 91%|██████████████████████████████████████████████████████████████████▍      | 91/100 [03:00<00:17,  1.92s/it]\r",
      " 92%|███████████████████████████████████████████████████████████████████▏     | 92/100 [03:02<00:15,  1.94s/it]\r",
      " 93%|███████████████████████████████████████████████████████████████████▉     | 93/100 [03:04<00:13,  1.93s/it]\r",
      " 94%|████████████████████████████████████████████████████████████████████▌    | 94/100 [03:06<00:11,  1.95s/it]\r",
      " 95%|█████████████████████████████████████████████████████████████████████▎   | 95/100 [03:08<00:09,  1.96s/it]\r",
      " 96%|██████████████████████████████████████████████████████████████████████   | 96/100 [03:10<00:07,  1.94s/it]\r",
      " 97%|██████████████████████████████████████████████████████████████████████▊  | 97/100 [03:12<00:05,  1.98s/it]\r",
      " 98%|███████████████████████████████████████████████████████████████████████▌ | 98/100 [03:14<00:03,  1.96s/it]\r",
      " 99%|████████████████████████████████████████████████████████████████████████▎| 99/100 [03:16<00:01,  1.92s/it]\r",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [03:18<00:00,  1.91s/it]\r",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [03:18<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall train split accuracy: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                  | 0/100 [00:00<?, ?it/s]\r",
      "  1%|▋                                                                         | 1/100 [00:04<08:04,  4.89s/it]\r",
      "  2%|█▍                                                                        | 2/100 [00:11<10:03,  6.16s/it]\r",
      "  3%|██▏                                                                       | 3/100 [00:21<12:34,  7.78s/it]\r",
      "  4%|██▉                                                                       | 4/100 [00:32<14:16,  8.92s/it]\r",
      "  5%|███▋                                                                      | 5/100 [00:44<16:12, 10.23s/it]\r",
      "  6%|████▍                                                                     | 6/100 [01:00<18:45, 11.98s/it]\r",
      "  7%|█████▏                                                                    | 7/100 [01:16<20:59, 13.54s/it]\r",
      "  8%|█████▉                                                                    | 8/100 [01:36<23:28, 15.31s/it]\r",
      "  9%|██████▋                                                                   | 9/100 [01:56<25:33, 16.86s/it]\r",
      " 10%|███████▎                                                                 | 10/100 [02:18<27:49, 18.54s/it]\r",
      " 11%|████████                                                                 | 11/100 [02:43<30:19, 20.44s/it]\r",
      " 12%|████████▊                                                                | 12/100 [03:11<33:13, 22.65s/it]\r",
      " 13%|█████████▍                                                               | 13/100 [03:38<34:46, 23.98s/it]\r",
      " 14%|██████████▏                                                              | 14/100 [04:08<37:08, 25.91s/it]\r",
      " 15%|██████████▉                                                              | 15/100 [04:32<35:46, 25.25s/it]\r",
      " 16%|███████████▋                                                             | 16/100 [04:49<31:53, 22.78s/it]\r",
      " 17%|████████████▍                                                            | 17/100 [05:06<29:21, 21.23s/it]\r",
      " 18%|█████████████▏                                                           | 18/100 [05:24<27:34, 20.18s/it]\r",
      " 19%|█████████████▊                                                           | 19/100 [05:46<27:46, 20.58s/it]\r",
      " 20%|██████████████▌                                                          | 20/100 [06:08<28:03, 21.04s/it]\r",
      " 21%|███████████████▎                                                         | 21/100 [06:31<28:36, 21.73s/it]\r",
      " 22%|████████████████                                                         | 22/100 [06:53<28:20, 21.80s/it]\r",
      " 23%|████████████████▊                                                        | 23/100 [07:18<29:20, 22.86s/it]\r",
      " 24%|█████████████████▌                                                       | 24/100 [07:46<30:55, 24.41s/it]\r",
      " 25%|██████████████████▎                                                      | 25/100 [08:15<32:03, 25.65s/it]\r",
      " 26%|██████████████████▉                                                      | 26/100 [08:44<32:55, 26.69s/it]\r",
      " 27%|███████████████████▋                                                     | 27/100 [09:12<32:58, 27.11s/it]\r",
      " 28%|████████████████████▍                                                    | 28/100 [09:44<34:21, 28.64s/it]\r",
      " 29%|█████████████████████▏                                                   | 29/100 [10:18<35:33, 30.04s/it]\r",
      " 30%|█████████████████████▉                                                   | 30/100 [10:49<35:30, 30.43s/it]\r",
      " 31%|██████████████████████▋                                                  | 31/100 [11:21<35:39, 31.01s/it]\r",
      " 32%|███████████████████████▎                                                 | 32/100 [11:54<35:33, 31.37s/it]\r",
      " 33%|████████████████████████                                                 | 33/100 [12:30<36:45, 32.92s/it]\r",
      " 34%|████████████████████████▊                                                | 34/100 [13:04<36:21, 33.05s/it]\r",
      " 35%|█████████████████████████▌                                               | 35/100 [13:38<36:12, 33.42s/it]\r",
      " 36%|██████████████████████████▎                                              | 36/100 [14:13<36:10, 33.92s/it]\r",
      " 37%|███████████████████████████                                              | 37/100 [14:48<35:56, 34.23s/it]\r",
      " 38%|███████████████████████████▋                                             | 38/100 [15:30<37:56, 36.71s/it]\r",
      " 39%|████████████████████████████▍                                            | 39/100 [16:14<39:17, 38.65s/it]\r",
      " 40%|█████████████████████████████▏                                           | 40/100 [16:52<38:38, 38.65s/it]\r",
      " 41%|█████████████████████████████▉                                           | 41/100 [17:36<39:24, 40.08s/it]\r",
      " 42%|██████████████████████████████▋                                          | 42/100 [18:19<39:47, 41.17s/it]\r",
      " 43%|███████████████████████████████▍                                         | 43/100 [19:07<40:52, 43.02s/it]\r",
      " 44%|████████████████████████████████                                         | 44/100 [19:50<40:15, 43.14s/it]\r",
      " 45%|████████████████████████████████▊                                        | 45/100 [20:39<41:02, 44.78s/it]\r",
      " 46%|█████████████████████████████████▌                                       | 46/100 [21:25<40:47, 45.33s/it]\r",
      " 47%|██████████████████████████████████▎                                      | 47/100 [22:25<43:52, 49.66s/it]\r",
      " 48%|███████████████████████████████████                                      | 48/100 [23:15<43:04, 49.70s/it]\r",
      " 49%|███████████████████████████████████▊                                     | 49/100 [24:06<42:37, 50.14s/it]\r",
      " 50%|████████████████████████████████████▌                                    | 50/100 [24:52<40:46, 48.94s/it]\r",
      " 51%|█████████████████████████████████████▏                                   | 51/100 [25:40<39:44, 48.67s/it]\r",
      " 52%|█████████████████████████████████████▉                                   | 52/100 [26:35<40:31, 50.66s/it]\r",
      " 53%|██████████████████████████████████████▋                                  | 53/100 [27:22<38:45, 49.49s/it]\r",
      " 54%|███████████████████████████████████████▍                                 | 54/100 [28:14<38:28, 50.18s/it]\r",
      " 55%|████████████████████████████████████████▏                                | 55/100 [29:10<39:01, 52.04s/it]\r",
      " 56%|████████████████████████████████████████▉                                | 56/100 [30:02<38:04, 51.92s/it]\r",
      " 57%|█████████████████████████████████████████▌                               | 57/100 [31:00<38:36, 53.87s/it]\r",
      " 58%|██████████████████████████████████████████▎                              | 58/100 [31:58<38:32, 55.05s/it]\r",
      " 59%|███████████████████████████████████████████                              | 59/100 [33:03<39:40, 58.07s/it]\r",
      " 60%|███████████████████████████████████████████▊                             | 60/100 [33:58<38:00, 57.00s/it]\r",
      " 61%|████████████████████████████████████████████▌                            | 61/100 [34:55<37:00, 56.94s/it]\r",
      " 62%|█████████████████████████████████████████████▎                           | 62/100 [35:54<36:26, 57.54s/it]\r",
      " 63%|█████████████████████████████████████████████▉                           | 63/100 [36:55<36:10, 58.66s/it]\r",
      " 64%|██████████████████████████████████████████████▋                          | 64/100 [37:50<34:36, 57.68s/it]\r",
      " 65%|███████████████████████████████████████████████▍                         | 65/100 [38:54<34:39, 59.42s/it]\r",
      " 66%|████████████████████████████████████████████████▏                        | 66/100 [39:55<33:55, 59.86s/it]\r",
      " 67%|████████████████████████████████████████████████▉                        | 67/100 [41:02<34:05, 62.00s/it]\r",
      " 68%|█████████████████████████████████████████████████▋                       | 68/100 [42:06<33:22, 62.58s/it]\r",
      " 69%|██████████████████████████████████████████████████▎                      | 69/100 [43:13<33:01, 63.93s/it]\r",
      " 70%|███████████████████████████████████████████████████                      | 70/100 [44:21<32:39, 65.33s/it]\r",
      " 71%|███████████████████████████████████████████████████▊                     | 71/100 [45:27<31:39, 65.50s/it]\r",
      " 72%|████████████████████████████████████████████████████▌                    | 72/100 [46:51<33:08, 71.01s/it]\r",
      " 73%|█████████████████████████████████████████████████████▎                   | 73/100 [48:06<32:30, 72.22s/it]\r",
      " 74%|██████████████████████████████████████████████████████                   | 74/100 [49:14<30:45, 70.99s/it]\r",
      " 75%|██████████████████████████████████████████████████████▊                  | 75/100 [50:27<29:51, 71.67s/it]\r",
      " 76%|███████████████████████████████████████████████████████▍                 | 76/100 [51:51<30:03, 75.16s/it]\r",
      " 77%|████████████████████████████████████████████████████████▏                | 77/100 [53:02<28:18, 73.85s/it]\r",
      " 78%|████████████████████████████████████████████████████████▉                | 78/100 [54:14<26:57, 73.50s/it]"
     ]
    }
   ],
   "source": [
    "args = dict()\n",
    "args['temperature'] = 1.0\n",
    "args['num_samples'] = 50\n",
    "args['metric'] = 'squad_v2'\n",
    "args['enable_brief'] = True\n",
    "\n",
    "args['p_true_hint'] = False\n",
    "args['enable_brief'] = True\n",
    "args['use_context'] = False\n",
    "args['max_new_tokens'] = 50\n",
    "\n",
    "args['brief_always'] = False\n",
    "args['brief_always'] = False\n",
    "args['num_generations'] = 10\n",
    "\n",
    "args['compute_p_true'] = True\n",
    "args['dataset_name'] = 'gsm8k'\n",
    "args['answerable_only'] = False\n",
    "args['p_true_num_fewshot'] = 20\n",
    "args['brief_prompt'] = 'default'\n",
    "\n",
    "args['get_training_set_generations'] = True\n",
    "args['compute_accuracy_at_all_temps'] = True\n",
    "args['get_training_set_generations_most_likely_only'] = True\n",
    "\n",
    "args['compute_uncertainties'] = True\n",
    "\n",
    "main(args, tokenizer, model)\n",
    "\n",
    "if args['compute_uncertainties']:\n",
    "    args['max_new_tokens'] = 50\n",
    "    args['use_num_generations'] = -1\n",
    "    args['recompute_accuracy'] = False\n",
    "    args['use_all_generations'] = True\n",
    "\n",
    "    args['entailment_model'] = 'deberta'\n",
    "    args['compute_uncertainties'] = False\n",
    "    args['reuse_entailment_model'] = False\n",
    "    args['compute_predictive_entropy'] = True\n",
    "\n",
    "    args['compute_p_true_in_compute_stage'] = False\n",
    "    args['compute_context_entails_response'] = False\n",
    "\n",
    "    args['strict_entailment'] = True\n",
    "    args['num_eval_samples'] = int(1e19)\n",
    "    args['compute_p_ik'] = True\n",
    "    args['compute_p_ik_answerable'] = False\n",
    "    args['dataset_name'] = 'gsm8k'\n",
    "    args['args_metric'] = 'squad_v2'\n",
    "\n",
    "    print(\"Args: %s\", args)\n",
    "    main_uncertain(args, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ffff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a4bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfec5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
